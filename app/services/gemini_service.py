"""
Gemini AI ì„œë¹„ìŠ¤ - í…ìŠ¤íŠ¸ ìƒì„±
- ë¶„ì•¼ ê°ì§€
- ìŠ¤í† ë¦¬ ìƒì„±
- ìº¡ì…˜ ìƒì„±
"""
from google import genai
from google.genai import types
import asyncio
from typing import Optional
import json
import re

from app.core.config import get_settings, SPECIALIZED_FIELDS, FIELD_HASHTAGS
from app.models.models import (
    FieldInfo, SpecializedField, Story, Scene, Dialogue,
    InstagramCaption, CharacterSettings, CharacterProfile, RuleSettings
)


class GeminiService:
    """Gemini AI ì„œë¹„ìŠ¤ â€” ì‹ í˜• google.genai SDK ì‚¬ìš©"""
    
    def __init__(self):
        settings = get_settings()
        self._api_key = settings.gemini_api_key or ""
        self.client = genai.Client(
            api_key=self._api_key,
            http_options=types.HttpOptions(timeout=180_000)  # 180ì´ˆ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
        ) if self._api_key else None
        self._default_model = "gemini-3-flash-preview"
        self.last_used_model: Optional[str] = None

    async def detect_field(self, keyword: str, model: str = "gemini-3-flash-preview") -> FieldInfo:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì—ì„œ ë¶„ì•¼, ê¸°ì¤€ ë…„ë„, ë²•ì • ê²€ì¦ í•„ìš”ì„± ìë™ ê°ì§€ - ëª¨ë¸ fallback ì§€ì›"""
        import logging
        import datetime
        logger = logging.getLogger(__name__)
        current_year_str = str(datetime.datetime.now().year)
        
        # Fallback ëª¨ë¸ ìˆœì„œ ì •ì˜
        FALLBACK_MODELS = {
            "gemini-3-pro-preview": ["gemini-3-flash-preview", "gemini-2.0-flash"],
            "gemini-3-flash-preview": ["gemini-2.0-flash"],
            "gemini-2.0-flash": []
        }
        
        models_to_try = [model] + FALLBACK_MODELS.get(model, ["gemini-2.0-flash"])
        
        prompt = f"""í‚¤ì›Œë“œ "{keyword}"ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        í˜„ì¬ ì‹œê°ì€ {current_year_str}ë…„ì…ë‹ˆë‹¤. íŠ¹ë³„í•œ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê¸°ì¤€ ë…„ë„ëŠ” {current_year_str}ë…„ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
        
        [ë¶„ì„ í•­ëª©]
        1. field: ì„¸ë¬´, ë²•ë¥ , ë…¸ë¬´, íšŒê³„, ë¶€ë™ì‚°ì •ì±…, ì˜í•™, ê¸ˆìœµ, êµìœ¡, ê¸°ìˆ , ì¼ë°˜ ì¤‘ í•˜ë‚˜
           - í‚¤ì›Œë“œì˜ í•µì‹¬ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”.
        2. target_year: í•´ë‹¹ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì¤€ ë…„ë„ (ì˜ˆ: 2025, 2026). 
           - í‚¤ì›Œë“œì— ë…„ë„ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ê·¸ ë…„ë„ë¥¼ ë”°ë¥´ê³ , ì—†ìœ¼ë©´ í˜„ì¬ ë…„ë„({current_year_str})ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ í•©ë‹ˆë‹¤.
        3. requires_legal_verification: ì •í™•í•œ ë²•ë ¹/ê·œì • í™•ì¸ì´ í•„ìˆ˜ì ì¸ì§€ ì—¬ë¶€ (true/false)
           - ë²•ë¥ , ì„¸ê¸ˆ, ì˜ë£Œ ë“± ì •í™•ì„±ì´ ì¤‘ìš”í•œ ë¶„ì•¼ëŠ” trueë¡œ ì„¤ì •
        4. reason: ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ì— ëŒ€í•œ ì§§ì€ ê·¼ê±° (í•œêµ­ì–´)
        
        [ì˜ˆì‹œ]
        í‚¤ì›Œë“œ: "ê±´ê°•í•œ ì‹ìŠµê´€" -> field: "ì¼ë°˜", target_year: "{current_year_str}"
        í‚¤ì›Œë“œ: "ì£¼ì‹ íˆ¬ì ì…ë¬¸" -> field: "ê¸ˆìœµ", target_year: "{current_year_str}"
        í‚¤ì›Œë“œ: "2025ë…„ ìƒì†ì„¸ ê°œì •ì•ˆ" -> field: "ì„¸ë¬´", target_year: "2025"
        
        [ì¶œë ¥ í˜•ì‹]
        {{
            "field": "ë¶„ì•¼",
            "target_year": "{current_year_str}",
            "requires_legal_verification": true,
            "reason": "í•œ ë‘ ë¬¸ì¥ ê·¼ê±°"
        }}"""

        for try_model in models_to_try:
            for attempt in range(1, 3):  # ëª¨ë¸ë‹¹ ìµœëŒ€ 2íšŒ ì‹œë„
                try:
                    logger.info(f"[detect_field] ì‹œë„ ì¤‘: {try_model} (attempt {attempt})")
                    response = await asyncio.wait_for(
                        asyncio.to_thread(
                            self.client.models.generate_content,
                            model=try_model,
                            contents=prompt
                        ),
                        timeout=30
                    )
                    text = response.text
                    match = re.search(r'\{.*\}', text, re.DOTALL)
                    if match:
                        data = json.loads(match.group())
                    else:
                        raise ValueError("JSON not found in response")
                    
                    self.last_used_model = try_model
                    logger.info(f"[detect_field] ì„±ê³µ: {try_model}")
                    return FieldInfo(
                        field=SpecializedField(data.get("field", "ì¼ë°˜")),
                        target_year=data.get("target_year", current_year_str),
                        requires_legal_verification=data.get("requires_legal_verification", False),
                        reason=data.get("reason"),
                        confidence_score=0.9
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"[detect_field] {try_model} íƒ€ì„ì•„ì›ƒ (attempt {attempt})")
                    if attempt < 2:
                        await asyncio.sleep(2)
                        continue
                except Exception as e:
                    err_str = str(e).lower()
                    is_transient = "504" in err_str or "503" in err_str or "unavailable" in err_str or "deadline" in err_str
                    logger.warning(f"[detect_field] {try_model} ì‹¤íŒ¨ (attempt {attempt}): {e}")
                    if is_transient and attempt < 2:
                        await asyncio.sleep(3)
                        continue
                break  # ë¹„ì¼ì‹œì  ì—ëŸ¬ â†’ ë‹¤ìŒ ëª¨ë¸ë¡œ
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì—ëŸ¬ê°€ ì•„ë‹Œ ê¸°ë³¸ê°’ â†’ ìë£Œ ìˆ˜ì§‘ì€ ê³„ì† ì§„í–‰)
        logger.error(f"[detect_field] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ â†’ ê¸°ë³¸ê°’(ì¼ë°˜) ë°˜í™˜")
        return FieldInfo(field=SpecializedField.GENERAL, target_year=current_year_str)

    @staticmethod
    def is_synopsis_keyword(keyword: str) -> bool:
        """ìŠ¤í† ë¦¬ ì‹œë†‰ì‹œìŠ¤ë¡œ ë³¼ ì…ë ¥ì¸ì§€ ì—¬ë¶€ (ìë£Œ ìˆ˜ì§‘/ë¶„ì•¼ê°ì§€ ìƒëµìš©)"""
        k = (keyword or "").strip()
        if len(k) >= 80:
            return True
        synopsis_keywords = ("ìŠ¤í† ë¦¬", "ì”¬", "ì¥ë©´", "ì¸ìŠ¤íƒ€íˆ°", "ë§Œë“¤", "ê·¸ë¦¬")
        return any(w in k for w in synopsis_keywords)

    async def collect_data(self, keyword: str, field_info: Optional[FieldInfo] = None, model: str = "gemini-3-flash-preview", expert_mode: bool = False) -> list:
        """ì£¼ì œì™€ ê´€ë ¨ëœ ìƒì„¸ ìë£Œ ìˆ˜ì§‘ (1íšŒ API í˜¸ì¶œë¡œ ë¶„ì•¼ íŒë‹¨ + ìë£Œ ìˆ˜ì§‘ ë™ì‹œ ìˆ˜í–‰)"""
        import logging
        logger = logging.getLogger(__name__)

        # ìŠ¤í† ë¦¬ ì‹œë†‰ì‹œìŠ¤ ê°ì§€
        if self.is_synopsis_keyword(keyword):
            logger.info("[collect_data] ìŠ¤í† ë¦¬ ì‹œë†‰ì‹œìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ API í˜¸ì¶œ ì—†ì´ í†µê³¼")
            return [{"title": "ìŠ¤í† ë¦¬ ì‹œë†‰ì‹œìŠ¤", "content": keyword}]

        FALLBACK_MODELS = {
            "gemini-3-pro-preview": ["gemini-3-flash-preview", "gemini-2.0-flash"],
            "gemini-3-flash-preview": ["gemini-2.0-flash"],
            "gemini-2.0-flash": []
        }
        models_to_try = [model] + FALLBACK_MODELS.get(model, ["gemini-2.0-flash"])

        import datetime
        current_year_str = str(datetime.datetime.now().year)

        # ë¶„ì•¼ íŒíŠ¸: field_infoê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ AIê°€ ìë™ íŒë‹¨
        field_hint = ""
        if field_info and field_info.field.value != "ì¼ë°˜":
            field_hint = f"(ì°¸ê³ : ì´ í‚¤ì›Œë“œëŠ” '{field_info.field.value}' ë¶„ì•¼ë¡œ íŒë‹¨ë¨, ê¸°ì¤€ ë…„ë„: {field_info.target_year})"

        if expert_mode:
            prompt = f"""ë‹¹ì‹ ì€ í•´ë‹¹ ë¶„ì•¼ì˜ ìµœê³  ìˆ˜ì¤€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ë¶„ì•¼(ì„¸ë¬´/ë²•ë¥ /ë…¸ë¬´/ê¸ˆìœµ/ì˜í•™/ë¶€ë™ì‚° ë“±)ë¥¼ ìë™ íŒë‹¨í•˜ê³ , ê·¸ ë¶„ì•¼ ì „ë¬¸ê°€ ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
{field_hint}

í‚¤ì›Œë“œ "{keyword}"ì— ëŒ€í•´ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìƒì„¸ ìë£Œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[í•µì‹¬ ì§€ì¹¨]
1. ê¸°ì¤€ ë…„ë„: {current_year_str}ë…„ ìµœì‹  ì •ë³´ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
2. í‚¤ì›Œë“œì˜ ë¶„ì•¼ë¥¼ ìë™ íŒë‹¨í•˜ì—¬ í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ê°€ì²˜ëŸ¼ ì‘ì„±í•˜ì„¸ìš”.
   - ì„¸ë¬´: ì„¸ë²• ì¡°í•­, ê³µì œ ê¸ˆì•¡, ì„¸ìœ¨, ì‹ ê³  ê¸°í•œ ë“± ì •í™•í•œ ìˆ«ì ê¸°ì¬
   - ë²•ë¥ : ë²•ì¡°ë¬¸, íŒë¡€ë²ˆí˜¸, ë¶„ìŸ ì‚¬ë¡€ í¬í•¨
   - ê¸ˆìœµ: ìˆ˜ìµë¥ , ìœ„í—˜ë„, ì„¸ì œ í˜œíƒ ë¹„êµ
   - ê¸°íƒ€: êµ¬ì²´ì  ìˆ˜ì¹˜, ì‚¬ë¡€, ê·¼ê±° í¬í•¨

[ì „ë¬¸ê°€ ëª¨ë“œ ìš”ì²­ ì‚¬í•­]
1. ì œëª©ê³¼ ìƒì„¸ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ **8~12ê°œ**ì˜ í•­ëª©ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
2. ê° í•­ëª©ì˜ ë³¸ë¬¸ì€ **200ì ì´ìƒ** ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
3. ì •í™•í•œ ë²•ë ¹ëª…/ì¡°í•­, ê¸ˆì•¡, ì„¸ìœ¨, ê¸°í•œ ë“± **êµ¬ì²´ì  ìˆ˜ì¹˜**ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
4. ì¼ë°˜ì¸ì´ ìì£¼ ë†“ì¹˜ëŠ” **ì‹¤ë¬´ íŒ**ì´ë‚˜ **ì£¼ì˜ì‚¬í•­**ì„ í¬í•¨í•˜ì„¸ìš”.
5. ê° í•­ëª©ì— **source_hint**(ê·¼ê±° ë²•ë ¹/ì¶œì²˜ íŒíŠ¸)ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
6. SNS ì½˜í…ì¸ (ì›¹íˆ°/ì¹´ë“œë‰´ìŠ¤)ë¡œ ì„¤ëª…í•˜ê¸° ì¢‹ì€ ì •ë³´ ìœ„ì£¼ë¡œ ì„ ì •í•˜ì„¸ìš”.

[ì¶œë ¥ í˜•ì‹ (JSON)]
[
    {{"title": "ìë£Œ ì œëª©1", "content": "ìƒì„¸ ì„¤ëª… ë‚´ìš© ({current_year_str}ë…„ ê¸°ì¤€)...", "source_hint": "ê·¼ê±° ë²•ë ¹ ë˜ëŠ” ì¶œì²˜ íŒíŠ¸"}},
    ...
]"""
        else:
            prompt = f"""í‚¤ì›Œë“œ "{keyword}"ì— ëŒ€í•´ SNS(ì¸ìŠ¤íƒ€ê·¸ë¨/ë¸”ë¡œê·¸)ìš© ì½˜í…ì¸  ì œì‘ì„ ìœ„í•œ ìƒì„¸ ìë£Œë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.
{field_hint}

[í•µì‹¬ ì§€ì¹¨]
1. ê¸°ì¤€ ë…„ë„: ë¬´ì¡°ê±´ ìµœì‹  {current_year_str}ë…„ (ë˜ëŠ” ê·¸ ì´í›„) ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
   - ì‚¬ìš©ìê°€ íŠ¹ì • ë…„ë„ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•˜ë‹¤ë©´, ìë™ìœ¼ë¡œ {current_year_str}ë…„ ê°œì • ë‚´ìš©ì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
2. ë¶„ì•¼ ìë™ íŒë‹¨: í‚¤ì›Œë“œë¥¼ ë³´ê³  í•´ë‹¹ ë¶„ì•¼(ì„¸ë¬´/ë²•ë¥ /ë…¸ë¬´/ê¸ˆìœµ/ì˜í•™/ë¶€ë™ì‚°/êµìœ¡/ê¸°ìˆ /ì¼ë°˜)ë¥¼ ìë™ íŒë‹¨í•˜ì—¬ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

[ìš”ì²­ ì‚¬í•­]
1. ì œëª©ê³¼ ìƒì„¸ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ 5~8ê°œì˜ í•­ëª©ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
2. ì‹¤ì œ ë²•ë ¹, ê°œì •ì•ˆ, ì •í™•í•œ ê³µì œ ê¸ˆì•¡ ë“± êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
3. ì¸ìŠ¤íƒ€ê·¸ë¨ ì¹´ë“œë‰´ìŠ¤ë‚˜ ì›¹íˆ°ìœ¼ë¡œ ì„¤ëª…í•˜ê¸° ì¢‹ì€ ì •ë³´ ìœ„ì£¼ë¡œ ì„ ì •í•˜ì„¸ìš”.
4. "ì¼ë°˜"ì ì¸ ë‚´ìš©ë³´ë‹¤ëŠ” "ì „ë¬¸ì ì´ê³  ì‹¤ì§ˆì ì¸ íŒ"ì„ í¬í•¨í•˜ì„¸ìš”.

[ì¶œë ¥ í˜•ì‹ (JSON)]
[
    {{"title": "ìë£Œ ì œëª©1", "content": "ìƒì„¸ ì„¤ëª… ë‚´ìš© ({current_year_str}ë…„ ê¸°ì¤€)..."}},
    ...
]"""
        
        last_error = None
        for try_model in models_to_try:
            for attempt in range(1, 4):  # ëª¨ë¸ë‹¹ ìµœëŒ€ 3íšŒ ì‹œë„
                try:
                    logger.info(f"[collect_data] ì‹œë„ ì¤‘: {try_model} (attempt {attempt})")
                    response = await asyncio.wait_for(
                        asyncio.to_thread(
                            self.client.models.generate_content,
                            model=try_model,
                            contents=prompt
                        ),
                        timeout=90
                    )
                    # JSON íŒŒì‹± (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì¶”ì¶œ)
                    match = re.search(r'\[.*\]', response.text, re.DOTALL)
                    if match:
                        result = json.loads(match.group())
                        self.last_used_model = try_model
                        logger.info(f"[collect_data] ì„±ê³µ: {try_model} (attempt {attempt}), {len(result)}ê°œ í•­ëª©")
                        return result
                    else:
                        raise ValueError("JSON list not found in response")

                except asyncio.TimeoutError:
                    last_error = "Gemini API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ (90ì´ˆ)"
                    logger.warning(f"[collect_data] {try_model} íƒ€ì„ì•„ì›ƒ (attempt {attempt})")
                    if attempt < 3:
                        wait = 3 * attempt
                        logger.info(f"[collect_data] {wait}ì´ˆ í›„ ì¬ì‹œë„")
                        await asyncio.sleep(wait)
                        continue
                except Exception as e:
                    last_error = e
                    err_str = str(e).lower()
                    is_transient = any(k in err_str for k in ["504", "503", "unavailable", "deadline", "rate", "429", "quota", "resource_exhausted"])
                    logger.warning(f"[collect_data] {try_model} ì‹¤íŒ¨ (attempt {attempt}): {e}")
                    if is_transient and attempt < 3:
                        wait = 5 * attempt
                        logger.info(f"[collect_data] ì¼ì‹œì  ì—ëŸ¬ â†’ {wait}ì´ˆ í›„ ì¬ì‹œë„")
                        await asyncio.sleep(wait)
                        continue
                break  # ë¹„ì¼ì‹œì  ì—ëŸ¬ â†’ ë‹¤ìŒ ëª¨ë¸ë¡œ

            if try_model != models_to_try[-1]:
                logger.info(f"[collect_data] ë‹¤ìŒ ëª¨ë¸ë¡œ ì „í™˜: {models_to_try[models_to_try.index(try_model)+1]}")
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ â†’ ì˜ˆì™¸ raise (ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì ì ˆí•œ HTTP ì½”ë“œë¡œ ì²˜ë¦¬)
        logger.error(f"[collect_data] ëª¨ë“  ëª¨ë¸Â·ì¬ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
        raise RuntimeError(f"ìë£Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {last_error}")

    @staticmethod
    def _build_character_names_prompt(
        character_names: str, 
        monologue_mode: bool = False, 
        monologue_character: str = "",
        characters_input: list = None
    ) -> str:
        """ìºë¦­í„° ì´ë¦„+ì—­í•  ì§€ì • í”„ë¡¬í”„íŠ¸ ìƒì„± (êµ¬ì¡°ì  ì…ë ¥ ìš°ì„ )"""
        
        ROLE_LABELS = {
            "expert": "ì „ë¬¸ê°€",
            "questioner": "ì§ˆë¬¸ì", 
            "helper": "ì¡°ë ¥ì",
            "none": "ì¼ë°˜ ë“±ì¥ì¸ë¬¼"
        }
        ROLE_INSTRUCTIONS = {
            "expert": "ì •ë³´ë¥¼ ì„¤ëª…í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤. ì§ˆë¬¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „ë¬¸ì  ë‚´ìš©ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.",
            "questioner": "ê¶ê¸ˆí•œ ì ì„ ì§§ê²Œ ë¬»ê³ , ë†€ë¼ê±°ë‚˜ ë°˜ì‘í•©ë‹ˆë‹¤. ì§ì ‘ ì „ë¬¸ ë‚´ìš©ì„ ì„¤ëª…í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.",
            "helper": "ë³´ì¡°ì ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ìƒí™©ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ë¥¼ ë³´ì¡°í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.",
            "none": "íŠ¹ë³„í•œ ì—­í•  ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ì— ì°¸ì—¬í•©ë‹ˆë‹¤. ìŠ¤í† ë¦¬ íë¦„ì— ë§ê²Œ ììœ ë¡­ê²Œ í–‰ë™í•©ë‹ˆë‹¤."
        }
        
        # êµ¬ì¡°ì  ì…ë ¥ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if characters_input and len(characters_input) > 0:
            valid_chars = [c for c in characters_input if c.get("name", "").strip()]
            if not valid_chars:
                return ""
            
            # ë…ë°± ëª¨ë“œ: ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì¼  ê²½ìš°ë§Œ (ìºë¦­í„° 1ëª…ì´ì–´ë„ ìë™ ë…ë°± ì•ˆ í•¨)
            is_monologue = monologue_mode
            if is_monologue:
                mono_name = monologue_character.strip() if monologue_character else valid_chars[0]["name"]
                return (
                    f"\n[ë“±ì¥ì¸ë¬¼ - ë…ë°± ëª¨ë“œ - í•„ìˆ˜]\n"
                    f"ìºë¦­í„°ëŠ” '{mono_name}' 1ëª…ë§Œ ë“±ì¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ìºë¦­í„°ë¥¼ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
                    f"'{mono_name}'ê°€ ì‹œì²­ì(ë…ì)ì—ê²Œ ì§ì ‘ ì„¤ëª…í•˜ëŠ” 1ì¸ ë…ë°± í˜•ì‹ì…ë‹ˆë‹¤.\n"
                    f"ëŒ€í™” ìƒëŒ€ ì—†ì´ í˜¼ìì„œ ëª¨ë“  ë‚´ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
                )
            
            # ë‹¤ì¤‘ ìºë¦­í„°: ì´ë¦„-ì—­í•  ëª…ì‹œì  ë§¤í•‘
            lines = ["\n[ë“±ì¥ì¸ë¬¼ ì´ë¦„ ë° ì—­í•  ì§€ì • - í•„ìˆ˜]"]
            lines.append("ì•„ë˜ ìºë¦­í„°ë§Œ ë“±ì¥ì‹œí‚¤ì„¸ìš”. ë‹¤ë¥¸ ì´ë¦„ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n")
            for c in valid_chars:
                name = c["name"].strip()
                role = c.get("role", "expert")
                role_label = ROLE_LABELS.get(role, "ì „ë¬¸ê°€")
                role_inst = ROLE_INSTRUCTIONS.get(role, "")
                lines.append(f"- '{name}': {role_label} ì—­í• . {role_inst}")
            lines.append("")
            lines.append("â˜… ì—­í• ì„ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”! ì „ë¬¸ê°€ê°€ ì§ˆë¬¸í•˜ê±°ë‚˜, ì§ˆë¬¸ìê°€ ì „ë¬¸ ë‚´ìš©ì„ ì„¤ëª…í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.")
            lines.append("â˜… ê° ì”¬ì˜ ëŒ€ì‚¬ì—ì„œ character í•„ë“œì— ìœ„ ì´ë¦„ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”.")
            return "\n".join(lines) + "\n"
        
        # í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ character_names ë¬¸ìì—´ ë°©ì‹
        if not character_names or not character_names.strip():
            return ""
        names = [n.strip() for n in character_names.split(",") if n.strip()]
        if not names:
            return ""

        is_monologue = monologue_mode
        mono_char = monologue_character.strip() if monologue_character else (names[0] if len(names) == 1 else "")

        if is_monologue and mono_char:
            return (
                f"\n[ë“±ì¥ì¸ë¬¼ - ë…ë°± ëª¨ë“œ - í•„ìˆ˜]\n"
                f"ìºë¦­í„°ëŠ” '{mono_char}' 1ëª…ë§Œ ë“±ì¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ìºë¦­í„°ë¥¼ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
                f"'{mono_char}'ê°€ ì‹œì²­ì(ë…ì)ì—ê²Œ ì§ì ‘ ì„¤ëª…í•˜ëŠ” 1ì¸ ë…ë°± í˜•ì‹ì…ë‹ˆë‹¤.\n"
                f"ëŒ€í™” ìƒëŒ€ ì—†ì´ í˜¼ìì„œ ëª¨ë“  ë‚´ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
            )
        else:
            names_str = ", ".join(names)
            lines = [
                "\n[ë“±ì¥ì¸ë¬¼ ì´ë¦„ ì§€ì • - í•„ìˆ˜]",
                f"ë‹¤ìŒ ì´ë¦„ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”. ë‹¤ë¥¸ ì´ë¦„ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”: {names_str}",
            ]
            if len(names) >= 2:
                lines.append(f"- '{names[0]}': ì „ë¬¸ê°€ ì—­í• . ì •ë³´ë¥¼ ì„¤ëª…í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤. ì§ˆë¬¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                lines.append(f"- '{names[1]}': ì§ˆë¬¸ì ì—­í• . ê¶ê¸ˆí•œ ì ì„ ì§§ê²Œ ë¬»ê³  ë°˜ì‘í•©ë‹ˆë‹¤. ì§ì ‘ ì„¤ëª…í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                for extra in names[2:]:
                    lines.append(f"- '{extra}': ì¡°ë ¥ì ì—­í• .")
                lines.append("â˜… ì—­í• ì„ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”!")
            else:
                lines.append(f"'{names[0]}'ì´(ê°€) ë©”ì¸ ì—­í• (ì „ë¬¸ê°€)ì…ë‹ˆë‹¤.")
            return "\n".join(lines) + "\n"

    async def generate_story(
        self,
        keyword: str,
        field_info: FieldInfo,
        collected_data: list,
        scene_count: int = 8,
        character_settings: Optional[CharacterSettings] = None,
        rule_settings: Optional[RuleSettings] = None,
        model: str = "gemini-3-flash-preview",
        character_names: str = "",
        characters_input: list = None,
        monologue_mode: bool = False,
        monologue_character: str = ""
    ) -> Story:
        """ê·œì¹™ ê¸°ë°˜ ìŠ¤í† ë¦¬ ìƒì„± - ëª¨ë¸ fallback ì§€ì›"""
        import logging
        logger = logging.getLogger(__name__)
        
        if not character_settings:
            character_settings = CharacterSettings()
        if not rule_settings:
            rule_settings = RuleSettings()

        # ë…ë°± ëª¨ë“œ: ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì¼  ê²½ìš°ë§Œ (ìºë¦­í„° 1ëª…ì´ì–´ë„ ìë™ ë…ë°± ì•ˆ í•¨)
        char_names_list = [n.strip() for n in character_names.split(",") if n.strip()] if character_names else []
        is_monologue = monologue_mode
        
        # Fallback ëª¨ë¸ ìˆœì„œ ì •ì˜
        FALLBACK_MODELS = {
            "gemini-3-pro-preview": ["gemini-3-flash-preview", "gemini-2.0-flash"],
            "gemini-3-flash-preview": ["gemini-2.0-flash"],
            "gemini-2.0-flash": []
        }
        models_to_try = [model] + FALLBACK_MODELS.get(model, ["gemini-2.0-flash"])
            
        data_str = "\n".join([f"- {d['title']}: {d['content']}" for d in collected_data])
        
        # ëŒ€ì‚¬ ê¸¸ì´ ì¦ê°€ (ì¶©ë¶„í•œ ì„¤ëª…ì„ ìœ„í•´)
        max_dialogue = max(rule_settings.max_dialogue_len, 50)
        max_narration = max(rule_settings.max_narration_len, 60)
        
        # ë…ë°±/ëŒ€í™” ëª¨ë“œ ë¶„ê¸° í…ìŠ¤íŠ¸ (f-string ì¤‘ì²© ë°©ì§€)
        if is_monologue:
            structure_text = (
                "- ìºë¦­í„°ê°€ í˜¼ì ì‹œì²­ì(ë…ì)ì—ê²Œ ì§ì ‘ ì„¤ëª…í•˜ëŠ” 1ì¸ ë…ë°± í˜•ì‹ì…ë‹ˆë‹¤.\n"
                "- ëŒ€í™” ìƒëŒ€ ì—†ì´ ëª¨ë“  ì”¬ì—ì„œ 1ëª…ì˜ ìºë¦­í„°ë§Œ ë“±ì¥í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ìºë¦­í„°ë¥¼ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
                '- ê° ì”¬ì˜ ëŒ€ì‚¬ëŠ” ì‹œì²­ìì—ê²Œ ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”. ì˜ˆ: "ì—¬ëŸ¬ë¶„, ì´ê±° ì•Œë©´ ì™„ì „ ë‹¬ë¼ì ¸ìš”!"\n'
                "- ê° ì”¬ë§ˆë‹¤ ìºë¦­í„°ì˜ ê°ì •ì„ í•œê¸€ë¡œ ì§€ì •í•˜ì„¸ìš”."
            )
        else:
            structure_text = (
                "- ìºë¦­í„°ë“¤ì´ ì‹¤ì œ ëŒ€í™”í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.\n"
                "- ê° ì”¬ë§ˆë‹¤ ìºë¦­í„°ì˜ ê°ì •ì„ í•œê¸€ë¡œ ì§€ì •í•˜ì„¸ìš” (ì¼ë°˜/ì›ƒìœ¼ë©°/ë°ê²Œ/ì§„ì§€í•˜ê²Œ/ë†€ë¼ë©°/í™”ë‚´ë©°/ìŠ¬í”„ê²Œ/ê±±ì •í•˜ë©°/ë‹¹í™©í•˜ë©°/ìì‹ ìˆê²Œ/ì†ì‚­ì´ë©°/ì†Œë¦¬ì¹˜ë©°/ê¶ê¸ˆí•´í•˜ë©°/ê°íƒ„í•˜ë©°/ê³ ë¯¼í•˜ë©°/ì¥ë‚œìŠ¤ëŸ½ê²Œ/ë¿Œë“¯í•˜ê²Œ/ì°¨ë¶„í•˜ê²Œ/ë‹¤ê¸‰í•˜ê²Œ/ë¶€ë„ëŸ¬ì›Œí•˜ë©°)."
            )
        
        char_names_prompt = self._build_character_names_prompt(character_names, monologue_mode, monologue_character, characters_input)
        
        # êµ¬ì¡°ì  ìºë¦­í„° ì…ë ¥ì´ ìˆìœ¼ë©´ ì—­í• ë³„ ì´ë¦„ì„ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜
        if characters_input and len(characters_input) > 0:
            valid_ci = [c for c in characters_input if c.get("name", "").strip()]
            expert_name = next((c["name"] for c in valid_ci if c.get("role") == "expert"), None)
            questioner_name = next((c["name"] for c in valid_ci if c.get("role") == "questioner"), None)
            char_setting_text = ""
            for c in valid_ci:
                role_label = {"expert": "ì „ë¬¸ê°€", "questioner": "ì§ˆë¬¸ì", "helper": "ì¡°ë ¥ì", "none": "ì¼ë°˜ ë“±ì¥ì¸ë¬¼"}.get(c.get("role", ""), "ì „ë¬¸ê°€")
                char_setting_text += f"- {c['name']}: {role_label}\n"
            dialogue_quality_text = f"""[ì¤‘ìš” ì§€ì¹¨ - ëŒ€í™” í’ˆì§ˆ]
1. **ì „ë¬¸ê°€ ëŒ€ì‚¬ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤!** 
   - "ê·¸ê±´ ì•ˆ ë¼ìš”." (X) â†’ ë„ˆë¬´ ì§§ìŒ
   - "ê·¸ ë°©ë²•ì€ ì´ëŸ° ì´ìœ ë¡œ íš¨ê³¼ì ì´ì—ìš”. êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”." (O) â†’ ì ì ˆí•¨
2. {expert_name or 'ì „ë¬¸ê°€'}ë§Œ ì „ë¬¸ ë‚´ìš©ì„ ì„¤ëª…/ë‹µë³€í•©ë‹ˆë‹¤. {questioner_name or 'ì§ˆë¬¸ì'}ê°€ ì „ë¬¸ ë‚´ìš©ì„ ì„¤ëª…í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!
3. {questioner_name or 'ì§ˆë¬¸ì'}ëŠ” ì§§ê²Œ ì§ˆë¬¸í•˜ê³  ë°˜ì‘(ë†€ëŒ, ê¶ê¸ˆ, ê°íƒ„ ë“±)ë§Œ í•©ë‹ˆë‹¤.
4. ë‚´ìš©ì´ ë§ìœ¼ë©´ 2~3ê°œ ì”¬ì— ë‚˜ëˆ ì„œ ì„¤ëª…í•´ë„ ë©ë‹ˆë‹¤. ì–µì§€ë¡œ í•œ ì”¬ì— ì••ì¶•í•˜ì§€ ë§ˆì„¸ìš”."""
        else:
            char_setting_text = f"- ì§ˆë¬¸ì ìœ í˜•: {character_settings.questioner_type}\n- ì „ë¬¸ê°€ ìœ í˜•: {character_settings.expert_type}\n"
            dialogue_quality_text = """[ì¤‘ìš” ì§€ì¹¨ - ëŒ€í™” í’ˆì§ˆ]
1. **ì „ë¬¸ê°€ ëŒ€ì‚¬ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤!** 
   - "ê·¸ê±´ ì•ˆ ë¼ìš”." (X) â†’ ë„ˆë¬´ ì§§ìŒ
   - "ê·¸ ë°©ë²•ì€ ì´ëŸ° ì´ìœ ë¡œ íš¨ê³¼ì ì´ì—ìš”. êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”." (O) â†’ ì ì ˆí•¨
2. ì§ˆë¬¸ìëŠ” ì§§ê²Œ, ì „ë¬¸ê°€ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•˜ëŠ” í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. ë‚´ìš©ì´ ë§ìœ¼ë©´ 2~3ê°œ ì”¬ì— ë‚˜ëˆ ì„œ ì„¤ëª…í•´ë„ ë©ë‹ˆë‹¤. ì–µì§€ë¡œ í•œ ì”¬ì— ì••ì¶•í•˜ì§€ ë§ˆì„¸ìš”."""
        
        prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì›¹íˆ° ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›¹íˆ° ìŠ¤í† ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ìë£Œ]
{data_str}

[ìºë¦­í„° ì„¤ì •]
{char_setting_text}
{char_names_prompt}

{dialogue_quality_text}

[ì œì•½ ì¡°ê±´]
1. ì´ ì”¬ ê°œìˆ˜: {scene_count} (í‘œì§€ 1ì¥ + ë³¸ë¬¸ {scene_count - 1}ì¥)
2. í•œ ìºë¦­í„° ëŒ€ì‚¬: {max_dialogue}ì ì´ë‚´ (ì¶©ë¶„íˆ í™œìš©í•˜ì„¸ìš”)
3. í•œ ì”¬ë‹¹ ë§í’ì„ : ìµœëŒ€ {rule_settings.max_bubbles_per_scene}ê°œ
4. ë‚˜ë ˆì´ì…˜: {max_narration}ì ì´ë‚´

[í‘œì§€ ì”¬ â€” ë°˜ë“œì‹œ scene_number: 0ìœ¼ë¡œ ìƒì„±]
- í‘œì§€(ì¸ë„¤ì¼)ëŠ” scene_numberë¥¼ ë°˜ë“œì‹œ 0ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
- ì£¼ì¸ê³µ(ì²« ë²ˆì§¸ ìºë¦­í„°) 1ëª…ë§Œ ë“±ì¥í•©ë‹ˆë‹¤.
- ëŒ€ì‚¬ëŠ” ë”± 1ê°œ: ì „ì²´ ìŠ¤í† ë¦¬ë¥¼ ëŒ€ë³€í•˜ëŠ” ì„íŒ©íŠ¸ ìˆê³  í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” í•œ ë§ˆë”” (ì˜ˆ: "ì´ê±° ì•Œë©´ ì¸ìƒì´ ë‹¬ë¼ì ¸ìš”!", "ëª¨ë¥´ë©´ ì†í•´! ì§€ê¸ˆ ì•Œë ¤ë“œë¦´ê²Œìš”")
- ë‚˜ë ˆì´ì…˜ì€ ì—†ìŠµë‹ˆë‹¤.
- image_prompt: ì£¼ì¸ê³µì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ì‹œì„ ì„ ë„ëŠ” í¬ì¦ˆ. ì •ë©´ ë˜ëŠ” ì•½ê°„ ì¸¡ë©´ ì•µê¸€. ë°°ê²½ì€ ì£¼ì œì™€ ì–´ìš¸ë¦¬ëŠ” ì‹¬í”Œí•œ ë°°ê²½. ë¯¸ë””ì—„ ìƒ· ë˜ëŠ” í´ë¡œì¦ˆì—….
- í‘œì •ê³¼ ê°ì •ì€ ìŠ¤í† ë¦¬ ì£¼ì œì— ë§ê²Œ ììœ ë¡­ê²Œ ì„ íƒ (ë†€ë€, ê¶ê¸ˆí•œ, ìì‹ ê° ìˆëŠ”, ë‹¹í™©í•œ, ì§„ì§€í•œ ë“± â€” ì£¼ì œê°€ ì¶©ê²©ì ì´ë©´ ë†€ë€ í‘œì •, ê¿€íŒì´ë©´ ìì‹ ê°, ê²½ê³ ì„±ì´ë©´ ê±±ì • ë“±)
- í‘œì§€ ì”¬ ë‹¤ìŒì— ë³¸ë¬¸ ì”¬ë“¤ì´ scene_number: 1ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.

[ì§€ì¹¨ - ë‚˜ë ˆì´ì…˜ ìŠ¤íƒ€ì¼]
- ë‚˜ë ˆì´ì…˜ì€ ì™„ì „í•œ ë¬¸ì¥ë³´ë‹¤ëŠ” 'í•µì‹¬ ìš”ì•½ ìŠ¤íƒ€ì¼'(ê°œì¡°ì‹, ëª…ì‚¬í˜• ì¢…ê²°)ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ì˜ˆì‹œ: "ì´ê²ƒë§Œìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." (X) -> "ì´ê²ƒë§Œìœ¼ë¡œëŠ” ë¶€ì¡±." (O)
- ì˜ˆì‹œ: "í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤." (X) -> "í•µì‹¬ í¬ì¸íŠ¸ ê¸°ì–µ." (O)
- êµ°ë”ë”ê¸° ì—†ëŠ” ì§§ê³  ê°„ê²°í•œ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[í•„ìˆ˜ êµ¬ì¡°]
{structure_text}
- ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.

[ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ â€” ë§¤ìš° ì¤‘ìš”]
ê° ì”¬ë§ˆë‹¤ "image_prompt" í•„ë“œë¥¼ ë°˜ë“œì‹œ ì‘ì„±í•˜ì„¸ìš”. ì´ê²ƒì€ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì—ê²Œ ì „ë‹¬ë˜ëŠ” ì‹œê° ë¬˜ì‚¬ì…ë‹ˆë‹¤.
scene_descriptionì€ ìŠ¤í† ë¦¬ ì„¤ëª…ì´ê³ , image_promptëŠ” ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ìƒì„¸í•œ ì‹œê° ì§€ì‹œì…ë‹ˆë‹¤.

image_prompt ì‘ì„± ê·œì¹™:
1. **í•œêµ­ì–´ë¡œ ì‘ì„±** (ë‚˜ì¤‘ì— ìë™ ë²ˆì—­ë¨)
2. **ëŒ€ì‚¬/í…ìŠ¤íŠ¸ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€** â€” ë§í’ì„ ì´ë‚˜ ê¸€ìì— ëŒ€í•œ ì–¸ê¸‰ ì—†ì´, ìˆœìˆ˜í•˜ê²Œ ê·¸ë¦¼ë§Œ ë¬˜ì‚¬
3. **êµ¬ì²´ì  ì‹œê° ìš”ì†Œë§Œ í¬í•¨**: ìºë¦­í„° ìœ„ì¹˜, í¬ì¦ˆ, í‘œì •, ë°°ê²½, ì¡°ëª…, êµ¬ë„, ë¶„ìœ„ê¸°
4. **ì¹´ë©”ë¼ ì•µê¸€** ëª…ì‹œ: ì˜ˆ) "ë¯¸ë””ì—„ ìƒ·", "í´ë¡œì¦ˆì—…", "ì „ì‹  ìƒ·", "ì•½ê°„ ìœ„ì—ì„œ ë‚´ë ¤ë‹¤ë³´ëŠ” ì•µê¸€"
5. **ìºë¦­í„°ë³„ í¬ì¦ˆ/ë™ì‘** êµ¬ì²´ì ìœ¼ë¡œ: "íŒ”ì§±ì„ ë¼ê³  ì„œìˆë‹¤", "ì±…ìƒì— ê¸°ëŒ€ì–´ ì„¤ëª…í•˜ê³  ìˆë‹¤"
6. **í‘œì •** êµ¬ì²´ì ìœ¼ë¡œ: "ë‹¹í™©í•œ í‘œì •ìœ¼ë¡œ ëˆˆì„ í¬ê²Œ ëœ¨ê³ ", "ìì‹ ê° ë„˜ì¹˜ëŠ” ë¯¸ì†Œ"
7. **ë°°ê²½/í™˜ê²½** ìƒì„¸íˆ: "ë°ì€ í˜•ê´‘ë“±ì´ ì¼œì§„ ì‚¬ë¬´ì‹¤", "ì°½ë°–ìœ¼ë¡œ ë„ì‹œ ì•¼ê²½ì´ ë³´ì´ëŠ”"
8. **ì¡°ëª…/ë¶„ìœ„ê¸°**: "ë”°ëœ»í•œ ì¡°ëª…", "ë°ì§€ë§Œ ìºë¦­í„° ê·¸ë¦¼ìê°€ ì§™ì€", "ì—­ê´‘ìœ¼ë¡œ ì‹¤ë£¨ì—£"
9. **80~150ì** ë²”ìœ„ë¡œ ì‘ì„±

image_prompt ì¢‹ì€ ì˜ˆì‹œ:
- "ì›¹íˆ° ìŠ¤íƒ€ì¼. ë°ì€ ì‚¬ë¬´ì‹¤ ë‚´ë¶€. ì „ë¬¸ê°€ê°€ ì±…ìƒ ì•ì— ì•‰ì•„ ì„œë¥˜ë¥¼ í¼ì¹˜ë©° ì„¤ëª…í•˜ê³  ìˆë‹¤. ë§ì€í¸ì— ì Šì€ ì—¬ì„±ì´ ê¶ê¸ˆí•œ í‘œì •ìœ¼ë¡œ ì•‰ì•„ ìˆë‹¤. ì±…ìƒ ìœ„ì— ë…¸íŠ¸ë¶ê³¼ ì„œë¥˜ê°€ ë†“ì—¬ ìˆë‹¤. í˜•ê´‘ë“± ì¡°ëª…, ë¯¸ë””ì—„ ìƒ·."
- "ì›¹íˆ° ìŠ¤íƒ€ì¼. ì¹´í˜ ë‚´ë¶€, ë”°ëœ»í•œ ì¡°ëª…. ë‘ ì‚¬ëŒì´ ë§ˆì£¼ ì•‰ì•„ ëŒ€í™” ì¤‘. ì „ë¬¸ê°€ëŠ” ìì‹ ê° ìˆëŠ” ë¯¸ì†Œë¡œ ì†ìœ¼ë¡œ ì œìŠ¤ì²˜ë¥¼ í•˜ê³ , ì§ˆë¬¸ìëŠ” ê³ ê°œë¥¼ ê°¸ì›ƒí•˜ë©° ê¶ê¸ˆí•´í•˜ëŠ” í‘œì •. ë°°ê²½ì— ì»¤í”¼ì”ê³¼ ì°½ë°– í’ê²½. ë¯¸ë””ì—„ ì™€ì´ë“œ ìƒ·."

image_prompt ë‚˜ìœ ì˜ˆì‹œ:
- "ì „ë¬¸ê°€ê°€ ì„¤ëª…í•©ë‹ˆë‹¤" (X â€” ë„ˆë¬´ ì§§ê³  ì‹œê° ì •ë³´ ì—†ìŒ)
- "ì „ë¬¸ê°€: 'ì´ ë°©ë²•ì´ ì¢‹ìŠµë‹ˆë‹¤'" (X â€” ëŒ€ì‚¬ê°€ í¬í•¨ë¨)

[ìºë¦­í„° ì™¸ëª¨ â€” ë§¤ìš° ì¤‘ìš”]
ê° ìºë¦­í„°ì— ëŒ€í•´ visual_identityë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
ì´ ì •ë³´ëŠ” ì´ë¯¸ì§€ ìƒì„± ì‹œ ëª¨ë“  ì”¬ì—ì„œ ë™ì¼í•œ ì™¸ëª¨ë¥¼ ìœ ì§€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
êµ¬ì²´ì ì´ê³  ì •í™•í•˜ê²Œ, ì•„ë˜ 12ê°€ì§€ ì†ì„±ì„ ëª¨ë‘ ì±„ì›Œì£¼ì„¸ìš”.
- gender: "male" ë˜ëŠ” "female"
- age_range: ì˜ˆ) "early 30s", "mid 40s"
- hair_style: ì˜ˆ) "short straight hair, side-parted to the left" (ê¸¸ì´, ìŠ¤íƒ€ì¼, ê°€ë¥´ë§ˆ ë°©í–¥)
- hair_color: ì˜ˆ) "jet black #1A1A1A" (ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ)
- skin_tone: ì˜ˆ) "warm beige, light tan" (ë°ê¸°ì™€ í†¤ í¬í•¨)
- eye_shape: ì˜ˆ) "almond-shaped, medium size, double eyelid"
- glasses: ê¸°ë³¸ê°’ì€ "none (no glasses)". ì•ˆê²½ì„ ì“°ëŠ” ìºë¦­í„°ëŠ” íŠ¹ë³„í•œ ì´ìœ ê°€ ì—†ìœ¼ë©´ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ëŒ€ë¶€ë¶„ì˜ ìºë¦­í„°ëŠ” ì•ˆê²½ì„ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.
- outfit: ì˜ˆ) "navy blue suit jacket, white dress shirt, blue striped tie" (ìƒì˜, í•˜ì˜, ë„¥íƒ€ì´ ë“± êµ¬ì²´ì )
- outfit_color: ì˜ˆ) "navy #1B2A4A jacket, white #FFFFFF shirt, blue #3B5998 tie" (ê° ë¶€ìœ„ë³„ í—¥ìŠ¤ì½”ë“œ)
- accessories: ì˜ˆ) "silver watch on left wrist, black leather belt" ë˜ëŠ” "none"
- body_type: ì˜ˆ) "slim build, average height"
- distinguishing_features: ì˜ˆ) "small mole on right cheek" ë˜ëŠ” "none"

[ì¶œë ¥ í˜•ì‹ (JSON)]
{{
    "title": "ì œëª©",
    "characters": [
        {{
            "name": "ì´ë¦„",
            "role": "ì—­í• (ì „ë¬¸ê°€/ì§ˆë¬¸ì/ì¡°ë ¥ì)",
            "appearance": "ì™¸ëª¨ ë¬˜ì‚¬ (1~2ë¬¸ì¥ ìš”ì•½)",
            "personality": "ì„±ê²©",
            "visual_identity": {{
                "gender": "male/female",
                "age_range": "ë‚˜ì´ëŒ€",
                "hair_style": "êµ¬ì²´ì  í—¤ì–´ìŠ¤íƒ€ì¼",
                "hair_color": "ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ",
                "skin_tone": "í”¼ë¶€í†¤",
                "eye_shape": "ëˆˆ í˜•íƒœ",
                "glasses": "ì•ˆê²½ ìœ ë¬´ ë° ìƒì„¸ ë˜ëŠ” none",
                "outfit": "ë³µì¥ ìƒì„¸",
                "outfit_color": "ë¶€ìœ„ë³„ ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ",
                "accessories": "ì•¡ì„¸ì„œë¦¬ ë˜ëŠ” none",
                "body_type": "ì²´í˜•",
                "distinguishing_features": "íŠ¹ì´ì‚¬í•­ ë˜ëŠ” none"
            }}
        }}
    ],
    "scenes": [
        {{
            "scene_number": 0,
            "scene_description": "í‘œì§€ â€” ì „ì²´ ìŠ¤í† ë¦¬ë¥¼ ëŒ€ë³€í•˜ëŠ” ì¥ë©´",
            "image_prompt": "ì£¼ì¸ê³µ í´ë¡œì¦ˆì—… ë˜ëŠ” ë¯¸ë””ì—„ ìƒ·. ìŠ¤í† ë¦¬ ì£¼ì œì— ë§ëŠ” í‘œì •(ë†€ë€/ê¶ê¸ˆí•œ/ìì‹ ê°/ê±±ì • ë“±), ì •ë©´ ì‘ì‹œ. ì£¼ì œì™€ ì–´ìš¸ë¦¬ëŠ” ì‹¬í”Œí•œ ë°°ê²½. 80~150ì",
            "dialogues": [
                {{"character": "ì£¼ì¸ê³µ ì´ë¦„", "text": "ì „ì²´ ìŠ¤í† ë¦¬ë¥¼ ëŒ€ë³€í•˜ëŠ” ì„íŒ©íŠ¸ í•œ ë§ˆë””", "emotion": "ìŠ¤í† ë¦¬ì— ë§ëŠ” ê°ì •"}}
            ],
            "narration": ""
        }},
        {{
            "scene_number": 1,
            "scene_description": "ì¥ë©´ ìŠ¤í† ë¦¬ ì„¤ëª… (ì–´ë–¤ ìƒí™©ì¸ì§€)",
            "image_prompt": "AI ì´ë¯¸ì§€ ìƒì„±ìš© ìƒì„¸ ì‹œê° ë¬˜ì‚¬ (ìºë¦­í„° ìœ„ì¹˜/í¬ì¦ˆ/í‘œì •, ë°°ê²½, ì¡°ëª…, êµ¬ë„ í¬í•¨. ëŒ€ì‚¬ ì ˆëŒ€ ê¸ˆì§€. 80~150ì)",
            "dialogues": [
                {{"character": "ì´ë¦„", "text": "ëŒ€ì‚¬({max_dialogue}ìë‚´)", "emotion": "í•œê¸€ ê°ì • (ì˜ˆ: ì›ƒìœ¼ë©°, ì§„ì§€í•˜ê²Œ, ë†€ë¼ë©°, í™”ë‚´ë©°, ìŠ¬í”„ê²Œ, ê±±ì •í•˜ë©°, ë‹¹í™©í•˜ë©°, ìì‹ ìˆê²Œ, ì†ì‚­ì´ë©°, ì†Œë¦¬ì¹˜ë©°, ì¼ë°˜)"}}
            ],
            "narration": "ë‚˜ë ˆì´ì…˜({max_narration}ìë‚´, ì„ íƒ)"
        }}
    ]
}}"""

        last_error = None
        for try_model in models_to_try:
            try:
                logger.info(f"[generate_story] ì‹œë„ ì¤‘: {try_model}")
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        self.client.models.generate_content,
                        model=try_model,
                        contents=prompt
                    ),
                    timeout=120
                )
                data = json.loads(re.search(r'\{.*\}', response.text, re.DOTALL).group())
                
                scenes = []
                for s in data.get("scenes", []):
                    dialogues = [Dialogue(**d) for d in s.get("dialogues", [])]
                    scene = Scene(
                        scene_number=s.get("scene_number"),
                        scene_description=s.get("scene_description"),
                        image_prompt=s.get("image_prompt"),
                        dialogues=dialogues,
                        narration=s.get("narration")
                    )
                    scene.warnings = self._validate_scene_density(scene, rule_settings)
                    scenes.append(scene)
                
                # ìºë¦­í„° íŒŒì‹± (visual_identity í¬í•¨)
                from app.models.models import VisualIdentity
                parsed_characters = []
                for c in data.get("characters", []):
                    vi_data = c.pop("visual_identity", None)
                    char = CharacterProfile(**c)
                    if vi_data and isinstance(vi_data, dict):
                        char.visual_identity = VisualIdentity(**vi_data)
                    parsed_characters.append(char)
                
                self.last_used_model = try_model
                logger.info(f"[generate_story] ì„±ê³µ: {try_model}, ì”¬ ìˆ˜: {len(scenes)}, ìºë¦­í„°: {len(parsed_characters)}")
                return Story(
                    title=data.get("title", keyword),
                    scenes=scenes,
                    characters=parsed_characters
                )
            except asyncio.TimeoutError:
                last_error = "ìŠ¤í† ë¦¬ ìƒì„± íƒ€ì„ì•„ì›ƒ (120ì´ˆ)"
                logger.warning(f"[generate_story] {try_model} íƒ€ì„ì•„ì›ƒ (120ì´ˆ)")
                continue
            except Exception as e:
                last_error = e
                logger.warning(f"[generate_story] {try_model} ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        raise Exception(f"ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(last_error)}")

    def _validate_scene_density(self, scene: Scene, rules: RuleSettings) -> list:
        """ì”¬ì˜ í…ìŠ¤íŠ¸ ë°€ë„ ê²€ì‚¬"""
        warnings = []
        for d in scene.dialogues:
            if len(d.text) > rules.max_dialogue_len:
                warnings.append(f"{d.character} ëŒ€ì‚¬ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(d.text)}ì > {rules.max_dialogue_len}ì)")
        
        if len(scene.dialogues) > rules.max_bubbles_per_scene:
            warnings.append(f"ë§í’ì„ ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({len(scene.dialogues)}ê°œ > {rules.max_bubbles_per_scene}ê°œ)")
            
        if scene.narration and len(scene.narration) > rules.max_narration_len:
            warnings.append(f"ë‚˜ë ˆì´ì…˜ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(scene.narration)}ì > {rules.max_narration_len}ì)")
            
        return warnings
    
    async def generate_caption(
        self,
        keyword: str,
        field: SpecializedField,
        story_summary: str,
        model: str = "gemini-3-flash-preview",
        character_names: list[str] | None = None
    ) -> InstagramCaption:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ ìƒì„± - ëª¨ë¸ fallback + ì¬ì‹œë„ + ìºë¦­í„°ëª… í›„ì²˜ë¦¬ ì œê±°"""
        import logging
        logger = logging.getLogger(__name__)

        # Fallback ëª¨ë¸ ìˆœì„œ (ë¹ ë¥¸ ëª¨ë¸ ìš°ì„ )
        FALLBACK_MODELS = {
            "gemini-3-pro-preview": ["gemini-3-flash-preview", "gemini-2.0-flash"],
            "gemini-3-flash-preview": ["gemini-2.0-flash"],
            "gemini-2.0-flash": []
        }
        models_to_try = [model] + FALLBACK_MODELS.get(model, ["gemini-2.0-flash"])
        
        # ìºë¦­í„°ëª… ê¸ˆì§€ ëª©ë¡ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        char_ban_text = ""
        if character_names:
            names_str = ", ".join(f"'{n}'" for n in character_names)
            char_ban_text = f"\n   - ë‹¤ìŒ ì´ë¦„ì€ ì›¹íˆ° ì† ê°€ìƒì¸ë¬¼ì´ë¯€ë¡œ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€: {names_str}"
        
        prompt = f"""ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
ì£¼ì œ: {keyword}
ë¶„ì•¼: {field.value}
ìŠ¤í† ë¦¬ ìš”ì•½: {story_summary}

[ìƒì„± ê·œì¹™]

1. í›… ë¬¸ì¥ (ì²« ì¤„)
   - ì´ëª¨ì§€ë¡œ ì‹œì‘
   - í˜¸ê¸°ì‹¬ ìœ ë°œ ë˜ëŠ” ë¬¸ì œ ì œê¸°
   - 15ì ë‚´ì™¸

2. ë³¸ë¬¸ ìº¡ì…˜
   - ì¹œê·¼í•œ ë§íˆ¬
   - ì£¼ì œì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½
   - CTA í¬í•¨ (ì €ì¥, ê³µìœ  ìœ ë„)
   - 3~5ë¬¸ì¥
   - ê°€ë…ì„±ì„ ìœ„í•´ 2~3ë¬¸ì¥ë§ˆë‹¤ ì¤„ ë°”ê¿ˆ(\\n)ì„ ë„£ì„ ê²ƒ
   - ê°•ì¡°ë‚˜ ë¶„ìœ„ê¸°ì— ë§ê²Œ ë³¸ë¬¸ ì¤‘ê°„ì— ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•  ê²ƒ (ì˜ˆ: ğŸ’¡, âœ…, ğŸ’°, ğŸ‘‹, ğŸ“Œ ë“±)
   - ì›¹íˆ° ì† ê°€ìƒ ìºë¦­í„° ì´ë¦„(ë“±ì¥ì¸ë¬¼ëª…)ì€ ì ˆëŒ€ ìº¡ì…˜ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”{char_ban_text}
   - ì£¼ì œì™€ í•µì‹¬ ì •ë³´ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”

3. ì „ë¬¸ê°€ Tip
   - í•µì‹¬ ì •ë³´ 1ì¤„ ìš”ì•½
   - ì‹¤ìš©ì ì¸ ì¡°ì–¸
   - 20ì ë‚´ì™¸

4. í•´ì‹œíƒœê·¸
   - 15~20ê°œ
   - ì£¼ì œ ê´€ë ¨ íƒœê·¸ í¬í•¨

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- hook, expert_tip: í•œ ì¤„.
- body: ë³¸ë¬¸ì€ ì—¬ëŸ¬ ì¤„ ê°€ëŠ¥. ì¤„ë°”ê¿ˆ(\\n)ê³¼ ì´ëª¨ì§€ë¥¼ í™œìš©í•´ ê°€ë…ì„± ìˆê²Œ ì‘ì„±.
ì˜ˆì‹œ:
{{
  "hook": "ğŸ”¥ í›… ë¬¸ì¥",
  "body": "ì²« ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤. ìŠ¤í† ë¦¬ë¥¼ ìš”ì•½í•´ ë“œë ¤ìš”.\\n\\në‘ ë²ˆì§¸ ë¬¸ë‹¨ì´ì—ìš” ğŸ’¡ í•µì‹¬ë§Œ ì „ë‹¬í•©ë‹ˆë‹¤.\\n\\nì €ì¥í•´ë‘ê³  í™œìš©í•´ë³´ì„¸ìš”! âœ…",
  "expert_tip": "ì „ë¬¸ê°€ íŒ",
  "hashtags": ["#íƒœê·¸1", "#íƒœê·¸2"]
}}"""

        for try_model in models_to_try:
            try:
                logger.info(f"[generate_caption] ì‹œë„ ì¤‘: {try_model}")
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        self.client.models.generate_content,
                        model=try_model,
                        contents=prompt
                    ),
                    timeout=30
                )
                text = response.text.strip()
                
                json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
                if json_match:
                    text = json_match.group(1)
                
                data = json.loads(text)
                
                # ë¶„ì•¼ë³„ ê¸°ë³¸ í•´ì‹œíƒœê·¸ ì¶”ê°€
                hashtags = data.get("hashtags", [])
                base_tags = FIELD_HASHTAGS.get(field.value, [])
                all_tags = list(set(hashtags + base_tags))[:20]
                
                hook = data.get("hook", "")
                body = data.get("body", "")
                expert_tip = data.get("expert_tip", "")
                
                # â˜… ìºë¦­í„°ëª… í›„ì²˜ë¦¬ ì œê±° (í”„ë¡¬í”„íŠ¸ ë¬´ì‹œ ëŒ€ë¹„ ì•ˆì „ì¥ì¹˜)
                if character_names:
                    for cname in character_names:
                        if not cname:
                            continue
                        # "ì „ë¬¸ê°€ 'ê¹€ì„¸ë¬´'ê°€" â†’ "ì „ë¬¸ê°€ê°€" íŒ¨í„´ ì œê±°
                        import re as _re
                        for quote_pat in [f"'{cname}'", f"'{cname}'", f'"{cname}"', f"ã€Œ{cname}ã€"]:
                            hook = hook.replace(quote_pat, "")
                            body = body.replace(quote_pat, "")
                            expert_tip = expert_tip.replace(quote_pat, "")
                        # ì´ë¦„ ìì²´ ì œê±°
                        hook = hook.replace(cname, "")
                        body = body.replace(cname, "")
                        expert_tip = expert_tip.replace(cname, "")
                    # ì—°ì† ê³µë°± ì •ë¦¬
                    hook = " ".join(hook.split())
                    body = _re.sub(r' +', ' ', body)
                    expert_tip = " ".join(expert_tip.split())
                
                self.last_used_model = try_model
                logger.info(f"[generate_caption] ì„±ê³µ: {try_model}")
                return InstagramCaption(
                    hook=hook,
                    body=body,
                    expert_tip=expert_tip,
                    hashtags=all_tags
                )
                
            except asyncio.TimeoutError:
                logger.warning(f"[generate_caption] {try_model} íƒ€ì„ì•„ì›ƒ (30ì´ˆ) â†’ ë‹¤ìŒ ëª¨ë¸ ì‹œë„")
            except Exception as e:
                logger.warning(f"[generate_caption] {try_model} ì‹¤íŒ¨: {str(e)}")
                if try_model != models_to_try[-1]:
                    await asyncio.sleep(1)
                    continue

        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìº¡ì…˜ ë°˜í™˜ (500 ì—ëŸ¬ ëŒ€ì‹ )
        logger.error(f"[generate_caption] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨, ê¸°ë³¸ ìº¡ì…˜ ë°˜í™˜")
        default_tags = FIELD_HASHTAGS.get(field.value, ["#ì›¹íˆ°", "#ì •ë³´", "#ê¿€íŒ"])
        return InstagramCaption(
            hook=f"ğŸ“Œ {keyword} ì•Œì•„ë³´ê¸°",
            body=f"{keyword}ì— ëŒ€í•´ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì •ë³´ë¥¼ ì›¹íˆ°ìœ¼ë¡œ ì •ë¦¬í–ˆì–´ìš”!\n\nì €ì¥í•´ë‘ê³  í•„ìš”í•  ë•Œ í™•ì¸í•´ë³´ì„¸ìš” âœ…",
            expert_tip=f"{keyword} ê´€ë ¨ ì „ë¬¸ê°€ íŒ",
            hashtags=default_tags[:20]
        )



    async def extract_style_from_image(self, image_data: bytes) -> dict:
        """ì´ë¯¸ì§€ì—ì„œ ìŠ¤íƒ€ì¼(ì¸ë¬¼/ë°°ê²½) ë¶„ì„ ë° ì¶”ì¶œ"""
        import logging
        logger = logging.getLogger(__name__)
        
        # STYLE_SYSTEM.md 3.1 Vision AI Analysis Prompt
        STYLE_EXTRACTION_PROMPT = """
        You are an expert visual style analyst for Korean webtoon/cartoon images.
        
        Analyze the uploaded image(s) and extract two separate style profiles:
        
        ## CHARACTER STYLE (ì¸ë¬¼ ìŠ¤íƒ€ì¼)
        Describe the following visual attributes of how characters are drawn:
        - line_style: outline thickness, sketch vs clean, ink quality
        - color_palette: skin tones (with hex codes), hair colors, clothing color tendencies
        - proportion: head-to-body ratio, eye size relative to face
        - shading: cel-shading, gradient, flat color, shadow style
        - lighting: direction, warmth, shadow intensity on characters
        - expression_style: how eyes/mouth are drawn, level of expressiveness
        
        ## BACKGROUND STYLE (ë°°ê²½ ìŠ¤íƒ€ì¼)  
        Describe the following visual attributes of backgrounds:
        - setting: type of location (office, outdoor, abstract, etc.)
        - color_palette: dominant colors with hex codes
        - lighting: ambient light color, direction, intensity
        - detail_level: photorealistic, simplified, abstract
        - depth: depth-of-field blur, flat, layered
        - texture: smooth gradient, watercolor, flat vector, etc.
        
        ## OUTPUT FORMAT
        Return ONLY valid JSON with these exact keys. Do not include markdown formatting (```json ... ```).
        {
          "character_style": {
            "prompt_block": "<one paragraph prompt that captures all character style attributes>",
            "visual_attributes": { "line_style": "...", "color_palette": "...", "proportion": "...", "shading": "...", "lighting": "...", "expression_style": "..." },
            "locked_attributes": ["<top 3-4 most distinctive attributes>"]
          },
          "background_style": {
            "prompt_block": "<one paragraph prompt that captures all background style attributes>",
            "visual_attributes": { "setting": "...", "color_palette": "...", "lighting": "...", "detail_level": "...", "depth": "...", "texture": "..." },
            "locked_attributes": ["<top 3-4 most distinctive attributes>"]
          }
        }
        """

        # ì´ë¯¸ì§€ MIME type ê°ì§€
        mime_type = "image/png"
        if image_data[:3] == b'\xff\xd8\xff':
            mime_type = "image/jpeg"
        elif image_data[:4] == b'\x89PNG':
            mime_type = "image/png"
        elif image_data[:4] == b'RIFF':
            mime_type = "image/webp"

        # ì‹ í˜• SDK: Part.from_bytesë¡œ ì´ë¯¸ì§€ ì „ë‹¬
        image_part = types.Part.from_bytes(data=image_data, mime_type=mime_type)

        # Fallback ëª¨ë¸ ìˆœì„œ (ì‚¬ìš©ì ìš”ì²­: 3.0 Pro ë“± ê³ ì„±ëŠ¥ ëª¨ë¸ ì „ìš©)
        models_to_try = ["gemini-3-pro-preview", "gemini-3-flash-preview"]

        for try_model in models_to_try:
            try:
                logger.info(f"[extract_style] ì‹œë„ ì¤‘: {try_model}")
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        self.client.models.generate_content,
                        model=try_model,
                        contents=[STYLE_EXTRACTION_PROMPT, image_part]
                    ),
                    timeout=60
                )
                
                text = response.text
                # ë¡œê¹… ì¶”ê°€ (ë””ë²„ê¹…ìš©)
                if len(text) < 200:
                    logger.debug(f"[extract_style] {try_model} ì‘ë‹µ(ì¼ë¶€): {text}")
                
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° ì‹œë„
                text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
                text = re.sub(r'^```\s*', '', text, flags=re.MULTILINE)
                text = re.sub(r'```\s*$', '', text, flags=re.MULTILINE)
                
                match = re.search(r'\{.*\}', text, re.DOTALL)
                if match:
                    result = json.loads(match.group())
                    logger.info(f"[extract_style] ì„±ê³µ: {try_model}")
                    return result
                else:
                    logger.error(f"[extract_style] JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ ë‚´ìš©: {text[:500]}...")
                    raise ValueError("JSON not found in response")
                    
            except Exception as e:
                logger.warning(f"[extract_style] {try_model} ì‹¤íŒ¨: {e}")
                if try_model != models_to_try[-1]:
                    continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        logger.error("[extract_style] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨")
        raise Exception("ìŠ¤íƒ€ì¼ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_gemini_service: Optional[GeminiService] = None

def get_gemini_service() -> GeminiService:
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiService()
    return _gemini_service

def get_gemini_client():
    """ì‹±ê¸€í†¤ GeminiServiceì˜ Client ë°˜í™˜ (ë§¤ë²ˆ ìƒˆë¡œ ë§Œë“¤ì§€ ì•Šê³  ì¬ì‚¬ìš©)"""
    return get_gemini_service().client


