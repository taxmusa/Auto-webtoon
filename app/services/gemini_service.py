"""
Gemini AI ì„œë¹„ìŠ¤ - í…ìŠ¤íŠ¸ ìƒì„±
- ë¶„ì•¼ ê°ì§€
- ìŠ¤í† ë¦¬ ìƒì„±
- ìº¡ì…˜ ìƒì„±
"""
import google.generativeai as genai
from typing import Optional
import json
import re

from app.core.config import get_settings, SPECIALIZED_FIELDS, FIELD_HASHTAGS
from app.models.models import (
    FieldInfo, SpecializedField, Story, Scene, Dialogue,
    InstagramCaption, CharacterSettings, CharacterProfile, RuleSettings
)


class GeminiService:
    """Gemini AI ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        settings = get_settings()
        if settings.gemini_api_key:
            genai.configure(api_key=settings.gemini_api_key)
        self.model = genai.GenerativeModel("gemini-2.0-flash")

    async def detect_field(self, keyword: str, model: str = "gemini-2.0-flash") -> FieldInfo:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì—ì„œ ë¶„ì•¼, ê¸°ì¤€ ë…„ë„, ë²•ì • ê²€ì¦ í•„ìš”ì„± ìë™ ê°ì§€ - ëª¨ë¸ fallback ì§€ì›"""
        import logging
        import datetime
        logger = logging.getLogger(__name__)
        current_year_str = str(datetime.datetime.now().year)
        
        # Fallback ëª¨ë¸ ìˆœì„œ ì •ì˜
        FALLBACK_MODELS = {
            "gemini-2.0-flash": ["gemini-2.5-flash", "gemini-3-flash-preview"],
            "gemini-2.5-pro": ["gemini-2.5-flash", "gemini-3-pro-preview"],
            "gemini-2.5-flash": ["gemini-3-flash-preview"],
            "gemini-3-pro-preview": ["gemini-3-flash-preview"],
            "gemini-3-flash-preview": []
        }
        
        models_to_try = [model] + FALLBACK_MODELS.get(model, [])
        
        prompt = f"""í‚¤ì›Œë“œ "{keyword}"ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        í˜„ì¬ ì‹œê°ì€ {current_year_str}ë…„ì…ë‹ˆë‹¤. íŠ¹ë³„í•œ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê¸°ì¤€ ë…„ë„ëŠ” {current_year_str}ë…„ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
        
        [ë¶„ì„ í•­ëª©]
        1. field: ì„¸ë¬´, ë²•ë¥ , ë…¸ë¬´, íšŒê³„, ë¶€ë™ì‚°ì •ì±…, ì¼ë°˜ ì¤‘ í•˜ë‚˜
           - íŠ¹íˆ 'ì„¸ê¸ˆ', 'ì ˆì„¸', 'ì¦ì—¬', 'ìƒì†', 'ê³µì œ', 'ì—°ë§ì •ì‚°', 'ë¶€ê°€ì„¸', 'ì¢…ì†Œì„¸' ë“± ì„¸ê¸ˆ ê´€ë ¨ í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ "ì„¸ë¬´"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
        2. target_year: í•´ë‹¹ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì¤€ ë…„ë„ (ì˜ˆ: 2025, 2026). 
           - í‚¤ì›Œë“œì— ë…„ë„ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ê·¸ ë…„ë„ë¥¼ ë”°ë¥´ê³ , ì—†ìœ¼ë©´ í˜„ì¬ ë…„ë„({current_year_str})ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ í•©ë‹ˆë‹¤.
        3. requires_legal_verification: ì •í™•í•œ ë²•ë ¹/ê·œì • í™•ì¸ì´ í•„ìˆ˜ì ì¸ì§€ ì—¬ë¶€ (true/false)
           - ì„¸ê¸ˆ ê³„ì‚°, ë²•ì  ì ˆì°¨ ë“±ì€ ë°˜ë“œì‹œ trueë¡œ ì„¤ì •
        4. reason: ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ì— ëŒ€í•œ ì§§ì€ ê·¼ê±° (í•œêµ­ì–´)
        
        [ì˜ˆì‹œ]
        í‚¤ì›Œë“œ: "2025ë…„ ìƒì†ì„¸ ê°œì •ì•ˆ" -> field: "ì„¸ë¬´", target_year: "2025"
        í‚¤ì›Œë“œ: "ì¦ì—¬ì„¸ ì ˆì„¸ ë°©ë²•" -> field: "ì„¸ë¬´", target_year: "{current_year_str}"
        
        [ì¶œë ¥ í˜•ì‹]
        {{
            "field": "ë¶„ì•¼",
            "target_year": "{current_year_str}",
            "requires_legal_verification": true,
            "reason": "í•œ ë‘ ë¬¸ì¥ ê·¼ê±°"
        }}"""

        for try_model in models_to_try:
            try:
                logger.info(f"[detect_field] ì‹œë„ ì¤‘: {try_model}")
                current_model = genai.GenerativeModel(try_model)
                response = await current_model.generate_content_async(prompt)
                text = response.text
                match = re.search(r'\{.*\}', text, re.DOTALL)
                if match:
                    data = json.loads(match.group())
                else:
                    raise ValueError("JSON not found in response")
                
                logger.info(f"[detect_field] ì„±ê³µ: {try_model}")
                return FieldInfo(
                    field=SpecializedField(data.get("field", "ì¼ë°˜")),
                    target_year=data.get("target_year", current_year_str),
                    requires_legal_verification=data.get("requires_legal_verification", False),
                    reason=data.get("reason"),
                    confidence_score=0.9
                )
            except Exception as e:
                logger.warning(f"[detect_field] {try_model} ì‹¤íŒ¨: {str(e)}")
                if try_model != models_to_try[-1]:
                    continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        logger.error(f"[detect_field] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨")
        return FieldInfo(field=SpecializedField.GENERAL, target_year=current_year_str)

    async def collect_data(self, keyword: str, field_info: FieldInfo, model: str = "gemini-2.0-flash") -> list:
        """ì£¼ì œì™€ ê´€ë ¨ëœ ìƒì„¸ ìë£Œ ìˆ˜ì§‘ (ì œëª© + ë³¸ë¬¸) - ëª¨ë¸ fallback ì§€ì›"""
        import logging
        logger = logging.getLogger(__name__)
        
        # Fallback ëª¨ë¸ ìˆœì„œ ì •ì˜
        FALLBACK_MODELS = {
            "gemini-2.0-flash": ["gemini-2.5-flash", "gemini-3-flash-preview"],
            "gemini-2.5-pro": ["gemini-2.5-flash", "gemini-3-pro-preview"],
            "gemini-2.5-flash": ["gemini-3-flash-preview"],
            "gemini-3-pro-preview": ["gemini-3-flash-preview"],
            "gemini-3-flash-preview": []
        }
        
        models_to_try = [model] + FALLBACK_MODELS.get(model, [])
        
        # ìµœì‹  ë…„ë„ ì£¼ì…
        import datetime
        current_year_str = str(datetime.datetime.now().year)

        prompt = f"""í‚¤ì›Œë“œ "{keyword}"ì— ëŒ€í•´ SNS(ì¸ìŠ¤íƒ€ê·¸ë¨/ë¸”ë¡œê·¸)ìš© ì½˜í…ì¸  ì œì‘ì„ ìœ„í•œ ìƒì„¸ ìë£Œë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.
        
        [í•µì‹¬ ì§€ì¹¨]
        1. ê¸°ì¤€ ë…„ë„: ë¬´ì¡°ê±´ ìµœì‹  {current_year_str}ë…„ (ë˜ëŠ” ê·¸ ì´í›„) ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
           - ì‚¬ìš©ìê°€ íŠ¹ì • ë…„ë„ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•˜ë‹¤ë©´, ìë™ìœ¼ë¡œ {current_year_str}ë…„ ê°œì • ë‚´ìš©ì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        2. ë¶„ì•¼ ìë™ íŒë‹¨: í‚¤ì›Œë“œë¥¼ ë³´ê³  ì„¸ë¬´, ë²•ë¥ , ë¶€ë™ì‚° ë“± ì „ë¬¸ ë¶„ì•¼ë¼ë©´ í•´ë‹¹ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
           (ì…ë ¥ëœ ë¶„ì•¼ ì°¸ê³ : {field_info.field.value}, ê¸°ì¤€ ë…„ë„: {field_info.target_year})
        
        [ìš”ì²­ ì‚¬í•­]
        1. ì œëª©ê³¼ ìƒì„¸ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ 5~8ê°œì˜ í•­ëª©ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
        2. ì‹¤ì œ ë²•ë ¹, ê°œì •ì•ˆ, ì •í™•í•œ ê³µì œ ê¸ˆì•¡ ë“± êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
        3. ì¸ìŠ¤íƒ€ê·¸ë¨ ì¹´ë“œë‰´ìŠ¤ë‚˜ ì›¹íˆ°ìœ¼ë¡œ ì„¤ëª…í•˜ê¸° ì¢‹ì€ ì •ë³´ ìœ„ì£¼ë¡œ ì„ ì •í•˜ì„¸ìš”.
        4. "ì¼ë°˜"ì ì¸ ë‚´ìš©ë³´ë‹¤ëŠ” "ì „ë¬¸ì ì´ê³  ì‹¤ì§ˆì ì¸ íŒ"ì„ í¬í•¨í•˜ì„¸ìš”.
        
        [ì¶œë ¥ í˜•ì‹ (JSON)]
        [
            {{"title": "ìë£Œ ì œëª©1", "content": "ìƒì„¸ ì„¤ëª… ë‚´ìš© ({current_year_str}ë…„ ê¸°ì¤€)..."}},
            ...
        ]"""
        
        last_error = None
        for try_model in models_to_try:
            try:
                logger.info(f"[collect_data] ì‹œë„ ì¤‘: {try_model}")
                current_model = genai.GenerativeModel(try_model)
                response = await current_model.generate_content_async(prompt)
                
                # JSON íŒŒì‹± (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì¶”ì¶œ)
                match = re.search(r'\[.*\]', response.text, re.DOTALL)
                if match:
                    result = json.loads(match.group())
                    logger.info(f"[collect_data] ì„±ê³µ: {try_model}, {len(result)}ê°œ í•­ëª©")
                    return result
                else:
                    raise ValueError("JSON list not found in response")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"[collect_data] {try_model} ì‹¤íŒ¨: {str(e)}")
                if try_model != models_to_try[-1]:
                    logger.info(f"[collect_data] ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„: {models_to_try[models_to_try.index(try_model)+1]}")
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        logger.error(f"[collect_data] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
        return [{"title": keyword, "content": f"ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ({last_error}) ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."}]

    @staticmethod
    def _build_character_names_prompt(character_names: str) -> str:
        """ìºë¦­í„° ì´ë¦„ ì§€ì • í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if not character_names or not character_names.strip():
            return ""
        names = [n.strip() for n in character_names.split(",") if n.strip()]
        if not names:
            return ""
        names_str = ", ".join(names)
        return (
            "\n[ë“±ì¥ì¸ë¬¼ ì´ë¦„ ì§€ì • - í•„ìˆ˜]\n"
            f"ë‹¤ìŒ ì´ë¦„ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”. ë‹¤ë¥¸ ì´ë¦„ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”: {names_str}\n"
            "ì²« ë²ˆì§¸ ì´ë¦„ì´ ë©”ì¸ ì—­í• (ì „ë¬¸ê°€)ì´ê³ , ë‚˜ë¨¸ì§€ëŠ” ë³´ì¡° ì—­í• ì…ë‹ˆë‹¤.\n"
        )

    async def generate_story(
        self,
        keyword: str,
        field_info: FieldInfo,
        collected_data: list,
        scene_count: int = 8,
        character_settings: Optional[CharacterSettings] = None,
        rule_settings: Optional[RuleSettings] = None,
        model: str = "gemini-2.0-flash",
        character_names: str = ""
    ) -> Story:
        """ê·œì¹™ ê¸°ë°˜ ìŠ¤í† ë¦¬ ìƒì„± - ëª¨ë¸ fallback ì§€ì›"""
        import logging
        logger = logging.getLogger(__name__)
        
        if not character_settings:
            character_settings = CharacterSettings()
        if not rule_settings:
            rule_settings = RuleSettings()
        
        # Fallback ëª¨ë¸ ìˆœì„œ ì •ì˜ (ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ìš°ì„ )
        FALLBACK_MODELS = {
            "gemini-2.0-flash": ["gemini-2.5-flash", "gemini-3-flash-preview"],
            "gemini-2.5-pro": ["gemini-2.5-flash", "gemini-3-pro-preview"],
            "gemini-2.5-flash": ["gemini-3-flash-preview"],
            "gemini-3-pro-preview": ["gemini-3-flash-preview"],
            "gemini-3-flash-preview": ["gemini-2.5-flash"]
        }
        models_to_try = [model] + FALLBACK_MODELS.get(model, ["gemini-2.5-flash", "gemini-3-flash-preview"])
            
        data_str = "\n".join([f"- {d['title']}: {d['content']}" for d in collected_data])
        
        # ëŒ€ì‚¬ ê¸¸ì´ ì¦ê°€ (ì¶©ë¶„í•œ ì„¤ëª…ì„ ìœ„í•´)
        max_dialogue = max(rule_settings.max_dialogue_len, 50)
        max_narration = max(rule_settings.max_narration_len, 60)
        
        prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì›¹íˆ° ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›¹íˆ° ìŠ¤í† ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ìë£Œ]
{data_str}

[ìºë¦­í„° ì„¤ì •]
- ì§ˆë¬¸ì ìœ í˜•: {character_settings.questioner_type}
- ì „ë¬¸ê°€ ìœ í˜•: {character_settings.expert_type}
{self._build_character_names_prompt(character_names)}

[ì¤‘ìš” ì§€ì¹¨ - ëŒ€í™” í’ˆì§ˆ]
1. **ì „ë¬¸ê°€ ëŒ€ì‚¬ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤!** 
   - "ì—° 4.6% ì´ìê°€ ë²•ì •." (X) â†’ ë„ˆë¬´ ì§§ìŒ
   - "ì—° 4.6% ì´ìœ¨ë¡œ ì´ìë¥¼ ì§€ê¸‰í•´ì•¼ ì¦ì—¬ë¡œ ë³´ì§€ ì•Šì•„ìš”." (O) â†’ ì ì ˆí•¨
2. ì§ˆë¬¸ìëŠ” ì§§ê²Œ, ì „ë¬¸ê°€ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•˜ëŠ” í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. ë‚´ìš©ì´ ë§ìœ¼ë©´ 2~3ê°œ ì”¬ì— ë‚˜ëˆ ì„œ ì„¤ëª…í•´ë„ ë©ë‹ˆë‹¤. ì–µì§€ë¡œ í•œ ì”¬ì— ì••ì¶•í•˜ì§€ ë§ˆì„¸ìš”.

[ì œì•½ ì¡°ê±´]
1. ì´ ì”¬ ê°œìˆ˜: {scene_count}
2. í•œ ìºë¦­í„° ëŒ€ì‚¬: {max_dialogue}ì ì´ë‚´ (ì¶©ë¶„íˆ í™œìš©í•˜ì„¸ìš”)
3. í•œ ì”¬ë‹¹ ë§í’ì„ : ìµœëŒ€ {rule_settings.max_bubbles_per_scene}ê°œ
4. ë‚˜ë ˆì´ì…˜: {max_narration}ì ì´ë‚´

[ì§€ì¹¨ - ë‚˜ë ˆì´ì…˜ ìŠ¤íƒ€ì¼]
- ë‚˜ë ˆì´ì…˜ì€ ì™„ì „í•œ ë¬¸ì¥ë³´ë‹¤ëŠ” 'í•µì‹¬ ìš”ì•½ ìŠ¤íƒ€ì¼'(ê°œì¡°ì‹, ëª…ì‚¬í˜• ì¢…ê²°)ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ì˜ˆì‹œ: "ë‹¨ìˆœíˆ ì°¨ìš©ì¦ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤." (X) -> "ë‹¨ìˆœíˆ ì°¨ìš©ì¦ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±." (O)
- ì˜ˆì‹œ: "ì‹¤ì œ ìƒí™˜ ë‚´ì—­ì´ ì¤‘ìš”í•©ë‹ˆë‹¤." (X) -> "ì‹¤ì œ ìƒí™˜ ë‚´ì—­ì´ ì¤‘ìš”." (O)
- êµ°ë”ë”ê¸° ì—†ëŠ” ì§§ê³  ê°„ê²°í•œ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[í•„ìˆ˜ êµ¬ì¡°]
- ìºë¦­í„°ë“¤ì´ ì‹¤ì œ ëŒ€í™”í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- ê° ì”¬ë§ˆë‹¤ ìºë¦­í„°ì˜ ê¸°ë¶„(neutral/happy/sad/surprised/serious/angry)ì„ ì§€ì •í•˜ì„¸ìš”.
- ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.

[ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ â€” ë§¤ìš° ì¤‘ìš”]
ê° ì”¬ë§ˆë‹¤ "image_prompt" í•„ë“œë¥¼ ë°˜ë“œì‹œ ì‘ì„±í•˜ì„¸ìš”. ì´ê²ƒì€ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì—ê²Œ ì „ë‹¬ë˜ëŠ” ì‹œê° ë¬˜ì‚¬ì…ë‹ˆë‹¤.
scene_descriptionì€ ìŠ¤í† ë¦¬ ì„¤ëª…ì´ê³ , image_promptëŠ” ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ìƒì„¸í•œ ì‹œê° ì§€ì‹œì…ë‹ˆë‹¤.

image_prompt ì‘ì„± ê·œì¹™:
1. **í•œêµ­ì–´ë¡œ ì‘ì„±** (ë‚˜ì¤‘ì— ìë™ ë²ˆì—­ë¨)
2. **ëŒ€ì‚¬/í…ìŠ¤íŠ¸ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€** â€” ë§í’ì„ ì´ë‚˜ ê¸€ìì— ëŒ€í•œ ì–¸ê¸‰ ì—†ì´, ìˆœìˆ˜í•˜ê²Œ ê·¸ë¦¼ë§Œ ë¬˜ì‚¬
3. **êµ¬ì²´ì  ì‹œê° ìš”ì†Œë§Œ í¬í•¨**: ìºë¦­í„° ìœ„ì¹˜, í¬ì¦ˆ, í‘œì •, ë°°ê²½, ì¡°ëª…, êµ¬ë„, ë¶„ìœ„ê¸°
4. **ì¹´ë©”ë¼ ì•µê¸€** ëª…ì‹œ: ì˜ˆ) "ë¯¸ë””ì—„ ìƒ·", "í´ë¡œì¦ˆì—…", "ì „ì‹  ìƒ·", "ì•½ê°„ ìœ„ì—ì„œ ë‚´ë ¤ë‹¤ë³´ëŠ” ì•µê¸€"
5. **ìºë¦­í„°ë³„ í¬ì¦ˆ/ë™ì‘** êµ¬ì²´ì ìœ¼ë¡œ: "íŒ”ì§±ì„ ë¼ê³  ì„œìˆë‹¤", "ì±…ìƒì— ê¸°ëŒ€ì–´ ì„¤ëª…í•˜ê³  ìˆë‹¤"
6. **í‘œì •** êµ¬ì²´ì ìœ¼ë¡œ: "ë‹¹í™©í•œ í‘œì •ìœ¼ë¡œ ëˆˆì„ í¬ê²Œ ëœ¨ê³ ", "ìì‹ ê° ë„˜ì¹˜ëŠ” ë¯¸ì†Œ"
7. **ë°°ê²½/í™˜ê²½** ìƒì„¸íˆ: "ë°ì€ í˜•ê´‘ë“±ì´ ì¼œì§„ ì‚¬ë¬´ì‹¤", "ì°½ë°–ìœ¼ë¡œ ë„ì‹œ ì•¼ê²½ì´ ë³´ì´ëŠ”"
8. **ì¡°ëª…/ë¶„ìœ„ê¸°**: "ë”°ëœ»í•œ ì¡°ëª…", "ë°ì§€ë§Œ ìºë¦­í„° ê·¸ë¦¼ìê°€ ì§™ì€", "ì—­ê´‘ìœ¼ë¡œ ì‹¤ë£¨ì—£"
9. **80~150ì** ë²”ìœ„ë¡œ ì‘ì„±

image_prompt ì¢‹ì€ ì˜ˆì‹œ:
- "ì›¹íˆ° ìŠ¤íƒ€ì¼. ë°ì€ ì‚¬ë¬´ì‹¤ ë‚´ë¶€. ì„¸ë¬´ì‚¬ê°€ ì±…ìƒ ì•ì— ì•‰ì•„ ì„œë¥˜ë¥¼ í¼ì¹˜ë©° ì„¤ëª…í•˜ê³  ìˆë‹¤. ë§ì€í¸ì— ì Šì€ ì—¬ì„±ì´ ê±±ì •ìŠ¤ëŸ¬ìš´ í‘œì •ìœ¼ë¡œ ì•‰ì•„ ìˆë‹¤. ì±…ìƒ ìœ„ì— ê³„ì‚°ê¸°ì™€ ì„œë¥˜ê°€ ë†“ì—¬ ìˆë‹¤. í˜•ê´‘ë“± ì¡°ëª…, ë¯¸ë””ì—„ ìƒ·."
- "ì›¹íˆ° ìŠ¤íƒ€ì¼. ì¹´í˜ ë‚´ë¶€, ë”°ëœ»í•œ ì¡°ëª…. ë‘ ì‚¬ëŒì´ ë§ˆì£¼ ì•‰ì•„ ëŒ€í™” ì¤‘. ì „ë¬¸ê°€ëŠ” ìì‹ ê° ìˆëŠ” ë¯¸ì†Œë¡œ ì†ìœ¼ë¡œ ì œìŠ¤ì²˜ë¥¼ í•˜ê³ , ì§ˆë¬¸ìëŠ” ê³ ê°œë¥¼ ê°¸ì›ƒí•˜ë©° ê¶ê¸ˆí•´í•˜ëŠ” í‘œì •. ë°°ê²½ì— ì»¤í”¼ì”ê³¼ ì°½ë°– í’ê²½. ë¯¸ë””ì—„ ì™€ì´ë“œ ìƒ·."

image_prompt ë‚˜ìœ ì˜ˆì‹œ:
- "ì„¸ë¬´ì‚¬ê°€ ì„¤ëª…í•©ë‹ˆë‹¤" (X â€” ë„ˆë¬´ ì§§ê³  ì‹œê° ì •ë³´ ì—†ìŒ)
- "ì„¸ë¬´ì‚¬: 'ì´ììœ¨ì€ 4.6%ì…ë‹ˆë‹¤'" (X â€” ëŒ€ì‚¬ê°€ í¬í•¨ë¨)

[ìºë¦­í„° ì™¸ëª¨ â€” ë§¤ìš° ì¤‘ìš”]
ê° ìºë¦­í„°ì— ëŒ€í•´ visual_identityë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
ì´ ì •ë³´ëŠ” ì´ë¯¸ì§€ ìƒì„± ì‹œ ëª¨ë“  ì”¬ì—ì„œ ë™ì¼í•œ ì™¸ëª¨ë¥¼ ìœ ì§€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
êµ¬ì²´ì ì´ê³  ì •í™•í•˜ê²Œ, ì•„ë˜ 12ê°€ì§€ ì†ì„±ì„ ëª¨ë‘ ì±„ì›Œì£¼ì„¸ìš”.
- gender: "male" ë˜ëŠ” "female"
- age_range: ì˜ˆ) "early 30s", "mid 40s"
- hair_style: ì˜ˆ) "short straight hair, side-parted to the left" (ê¸¸ì´, ìŠ¤íƒ€ì¼, ê°€ë¥´ë§ˆ ë°©í–¥)
- hair_color: ì˜ˆ) "jet black #1A1A1A" (ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ)
- skin_tone: ì˜ˆ) "warm beige, light tan" (ë°ê¸°ì™€ í†¤ í¬í•¨)
- eye_shape: ì˜ˆ) "almond-shaped, medium size, double eyelid"
- glasses: ê¸°ë³¸ê°’ì€ "none (no glasses)". ì•ˆê²½ì„ ì“°ëŠ” ìºë¦­í„°ëŠ” íŠ¹ë³„í•œ ì´ìœ ê°€ ì—†ìœ¼ë©´ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ëŒ€ë¶€ë¶„ì˜ ìºë¦­í„°ëŠ” ì•ˆê²½ì„ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.
- outfit: ì˜ˆ) "navy blue suit jacket, white dress shirt, blue striped tie" (ìƒì˜, í•˜ì˜, ë„¥íƒ€ì´ ë“± êµ¬ì²´ì )
- outfit_color: ì˜ˆ) "navy #1B2A4A jacket, white #FFFFFF shirt, blue #3B5998 tie" (ê° ë¶€ìœ„ë³„ í—¥ìŠ¤ì½”ë“œ)
- accessories: ì˜ˆ) "silver watch on left wrist, black leather belt" ë˜ëŠ” "none"
- body_type: ì˜ˆ) "slim build, average height"
- distinguishing_features: ì˜ˆ) "small mole on right cheek" ë˜ëŠ” "none"

[ì¶œë ¥ í˜•ì‹ (JSON)]
{{
    "title": "ì œëª©",
    "characters": [
        {{
            "name": "ì´ë¦„",
            "role": "ì—­í• (ì „ë¬¸ê°€/ì§ˆë¬¸ì/ì¡°ë ¥ì)",
            "appearance": "ì™¸ëª¨ ë¬˜ì‚¬ (1~2ë¬¸ì¥ ìš”ì•½)",
            "personality": "ì„±ê²©",
            "visual_identity": {{
                "gender": "male/female",
                "age_range": "ë‚˜ì´ëŒ€",
                "hair_style": "êµ¬ì²´ì  í—¤ì–´ìŠ¤íƒ€ì¼",
                "hair_color": "ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ",
                "skin_tone": "í”¼ë¶€í†¤",
                "eye_shape": "ëˆˆ í˜•íƒœ",
                "glasses": "ì•ˆê²½ ìœ ë¬´ ë° ìƒì„¸ ë˜ëŠ” none",
                "outfit": "ë³µì¥ ìƒì„¸",
                "outfit_color": "ë¶€ìœ„ë³„ ìƒ‰ìƒ + í—¥ìŠ¤ì½”ë“œ",
                "accessories": "ì•¡ì„¸ì„œë¦¬ ë˜ëŠ” none",
                "body_type": "ì²´í˜•",
                "distinguishing_features": "íŠ¹ì´ì‚¬í•­ ë˜ëŠ” none"
            }}
        }}
    ],
    "scenes": [
        {{
            "scene_number": 1,
            "scene_description": "ì¥ë©´ ìŠ¤í† ë¦¬ ì„¤ëª… (ì–´ë–¤ ìƒí™©ì¸ì§€)",
            "image_prompt": "AI ì´ë¯¸ì§€ ìƒì„±ìš© ìƒì„¸ ì‹œê° ë¬˜ì‚¬ (ìºë¦­í„° ìœ„ì¹˜/í¬ì¦ˆ/í‘œì •, ë°°ê²½, ì¡°ëª…, êµ¬ë„ í¬í•¨. ëŒ€ì‚¬ ì ˆëŒ€ ê¸ˆì§€. 80~150ì)",
            "dialogues": [
                {{"character": "ì´ë¦„", "text": "ëŒ€ì‚¬({max_dialogue}ìë‚´)", "emotion": "ê¸°ë¶„"}}
            ],
            "narration": "ë‚˜ë ˆì´ì…˜({max_narration}ìë‚´, ì„ íƒ)"
        }}
    ]
}}"""

        last_error = None
        for try_model in models_to_try:
            try:
                logger.info(f"[generate_story] ì‹œë„ ì¤‘: {try_model}")
                current_model = genai.GenerativeModel(try_model)
                response = await current_model.generate_content_async(prompt)
                data = json.loads(re.search(r'\{.*\}', response.text, re.DOTALL).group())
                
                scenes = []
                for s in data.get("scenes", []):
                    dialogues = [Dialogue(**d) for d in s.get("dialogues", [])]
                    scene = Scene(
                        scene_number=s.get("scene_number"),
                        scene_description=s.get("scene_description"),
                        image_prompt=s.get("image_prompt"),
                        dialogues=dialogues,
                        narration=s.get("narration")
                    )
                    scene.warnings = self._validate_scene_density(scene, rule_settings)
                    scenes.append(scene)
                
                # ìºë¦­í„° íŒŒì‹± (visual_identity í¬í•¨)
                from app.models.models import VisualIdentity
                parsed_characters = []
                for c in data.get("characters", []):
                    vi_data = c.pop("visual_identity", None)
                    char = CharacterProfile(**c)
                    if vi_data and isinstance(vi_data, dict):
                        char.visual_identity = VisualIdentity(**vi_data)
                    parsed_characters.append(char)
                
                logger.info(f"[generate_story] ì„±ê³µ: {try_model}, ì”¬ ìˆ˜: {len(scenes)}, ìºë¦­í„°: {len(parsed_characters)}")
                return Story(
                    title=data.get("title", keyword),
                    scenes=scenes,
                    characters=parsed_characters
                )
            except Exception as e:
                last_error = e
                logger.warning(f"[generate_story] {try_model} ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        raise Exception(f"ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(last_error)}")

    def _validate_scene_density(self, scene: Scene, rules: RuleSettings) -> list:
        """ì”¬ì˜ í…ìŠ¤íŠ¸ ë°€ë„ ê²€ì‚¬"""
        warnings = []
        for d in scene.dialogues:
            if len(d.text) > rules.max_dialogue_len:
                warnings.append(f"{d.character} ëŒ€ì‚¬ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(d.text)}ì > {rules.max_dialogue_len}ì)")
        
        if len(scene.dialogues) > rules.max_bubbles_per_scene:
            warnings.append(f"ë§í’ì„ ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({len(scene.dialogues)}ê°œ > {rules.max_bubbles_per_scene}ê°œ)")
            
        if scene.narration and len(scene.narration) > rules.max_narration_len:
            warnings.append(f"ë‚˜ë ˆì´ì…˜ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(scene.narration)}ì > {rules.max_narration_len}ì)")
            
        return warnings
    
    async def generate_caption(
        self,
        keyword: str,
        field: SpecializedField,
        story_summary: str
    ) -> InstagramCaption:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ ìƒì„±"""
        
        prompt = f"""ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
ì£¼ì œ: {keyword}
ë¶„ì•¼: {field.value}
ìŠ¤í† ë¦¬ ìš”ì•½: {story_summary}

[ìƒì„± ê·œì¹™]

1. í›… ë¬¸ì¥ (ì²« ì¤„)
   - ì´ëª¨ì§€ë¡œ ì‹œì‘
   - í˜¸ê¸°ì‹¬ ìœ ë°œ ë˜ëŠ” ë¬¸ì œ ì œê¸°
   - 15ì ë‚´ì™¸

2. ë³¸ë¬¸ ìº¡ì…˜
   - ì¹œê·¼í•œ ë§íˆ¬
   - ìŠ¤í† ë¦¬ ë‚´ìš© ìš”ì•½
   - CTA í¬í•¨ (ì €ì¥, ê³µìœ  ìœ ë„)
   - 3~5ë¬¸ì¥

3. ì „ë¬¸ê°€ Tip
   - í•µì‹¬ ì •ë³´ 1ì¤„ ìš”ì•½
   - ì‹¤ìš©ì ì¸ ì¡°ì–¸
   - 20ì ë‚´ì™¸

4. í•´ì‹œíƒœê·¸
   - 15~20ê°œ
   - ì£¼ì œ ê´€ë ¨ íƒœê·¸ í¬í•¨

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "hook": "ğŸ”¥ í›… ë¬¸ì¥",
  "body": "ë³¸ë¬¸ ìº¡ì…˜",
  "expert_tip": "ì „ë¬¸ê°€ íŒ",
  "hashtags": ["#íƒœê·¸1", "#íƒœê·¸2"]
}}"""

        try:
            response = await self.model.generate_content_async(prompt)
            text = response.text.strip()
            
            json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if json_match:
                text = json_match.group(1)
            
            data = json.loads(text)
            
            # ë¶„ì•¼ë³„ ê¸°ë³¸ í•´ì‹œíƒœê·¸ ì¶”ê°€
            hashtags = data.get("hashtags", [])
            base_tags = FIELD_HASHTAGS.get(field.value, [])
            all_tags = list(set(hashtags + base_tags))[:20]
            
            return InstagramCaption(
                hook=data.get("hook", ""),
                body=data.get("body", ""),
                expert_tip=data.get("expert_tip", ""),
                hashtags=all_tags
            )
            
        except Exception as e:
            return InstagramCaption(
                hook=f"ğŸ”¥ {keyword} í•µì‹¬ ì •ë¦¬!",
                body=f"{keyword}ì— ëŒ€í•´ ì•Œì•„ë´¤ì–´ìš”. ì €ì¥í•´ë‘ê³  ì°¸ê³ í•˜ì„¸ìš”!",
                expert_tip="ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ë©´ ë” ì •í™•í•´ìš”!",
                hashtags=FIELD_HASHTAGS.get(field.value, ["#ì •ë³´", "#ê¿€íŒ"])
            )



    async def extract_style_from_image(self, image_data: bytes) -> dict:
        """ì´ë¯¸ì§€ì—ì„œ ìŠ¤íƒ€ì¼(ì¸ë¬¼/ë°°ê²½) ë¶„ì„ ë° ì¶”ì¶œ"""
        import logging
        logger = logging.getLogger(__name__)
        
        # STYLE_SYSTEM.md 3.1 Vision AI Analysis Prompt
        STYLE_EXTRACTION_PROMPT = """
        You are an expert visual style analyst for Korean webtoon/cartoon images.
        
        Analyze the uploaded image(s) and extract two separate style profiles:
        
        ## CHARACTER STYLE (ì¸ë¬¼ ìŠ¤íƒ€ì¼)
        Describe the following visual attributes of how characters are drawn:
        - line_style: outline thickness, sketch vs clean, ink quality
        - color_palette: skin tones (with hex codes), hair colors, clothing color tendencies
        - proportion: head-to-body ratio, eye size relative to face
        - shading: cel-shading, gradient, flat color, shadow style
        - lighting: direction, warmth, shadow intensity on characters
        - expression_style: how eyes/mouth are drawn, level of expressiveness
        
        ## BACKGROUND STYLE (ë°°ê²½ ìŠ¤íƒ€ì¼)  
        Describe the following visual attributes of backgrounds:
        - setting: type of location (office, outdoor, abstract, etc.)
        - color_palette: dominant colors with hex codes
        - lighting: ambient light color, direction, intensity
        - detail_level: photorealistic, simplified, abstract
        - depth: depth-of-field blur, flat, layered
        - texture: smooth gradient, watercolor, flat vector, etc.
        
        ## OUTPUT FORMAT
        Return ONLY valid JSON with these exact keys. Do not include markdown formatting (```json ... ```).
        {
          "character_style": {
            "prompt_block": "<one paragraph prompt that captures all character style attributes>",
            "visual_attributes": { "line_style": "...", "color_palette": "...", "proportion": "...", "shading": "...", "lighting": "...", "expression_style": "..." },
            "locked_attributes": ["<top 3-4 most distinctive attributes>"]
          },
          "background_style": {
            "prompt_block": "<one paragraph prompt that captures all background style attributes>",
            "visual_attributes": { "setting": "...", "color_palette": "...", "lighting": "...", "detail_level": "...", "depth": "...", "texture": "..." },
            "locked_attributes": ["<top 3-4 most distinctive attributes>"]
          }
        }
        """

        # ì´ë¯¸ì§€ MIME type ê°ì§€
        mime_type = "image/png"
        if image_data[:3] == b'\xff\xd8\xff':
            mime_type = "image/jpeg"
        elif image_data[:4] == b'\x89PNG':
            mime_type = "image/png"
        elif image_data[:4] == b'RIFF':
            mime_type = "image/webp"

        # inline_data í˜•íƒœë¡œ ì´ë¯¸ì§€ ì „ë‹¬ (PIL ë³€í™˜ ì—†ì´ ì§ì ‘ bytes ì‚¬ìš©)
        image_part = {
            "inline_data": {
                "mime_type": mime_type,
                "data": image_data
            }
        }

        # Fallback ëª¨ë¸ ìˆœì„œ (ì‚¬ìš©ì ìš”ì²­: 3.0 Pro ë“± ê³ ì„±ëŠ¥ ëª¨ë¸ ì „ìš©)
        # model_list.txt í™•ì¸ ê²°ê³¼ 1.5-proëŠ” ì—†ìŒ. 2.5-pro ì‚¬ìš©.
        models_to_try = ["gemini-3-pro-preview", "gemini-2.5-pro", "gemini-2.0-flash"]

        for try_model in models_to_try:
            try:
                logger.info(f"[extract_style] ì‹œë„ ì¤‘: {try_model}")
                model = genai.GenerativeModel(try_model)
                response = await model.generate_content_async([STYLE_EXTRACTION_PROMPT, image_part])
                
                text = response.text
                # ë¡œê¹… ì¶”ê°€ (ë””ë²„ê¹…ìš©)
                if len(text) < 200:
                    logger.debug(f"[extract_style] {try_model} ì‘ë‹µ(ì¼ë¶€): {text}")
                
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° ì‹œë„
                text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
                text = re.sub(r'^```\s*', '', text, flags=re.MULTILINE)
                text = re.sub(r'```\s*$', '', text, flags=re.MULTILINE)
                
                match = re.search(r'\{.*\}', text, re.DOTALL)
                if match:
                    result = json.loads(match.group())
                    logger.info(f"[extract_style] ì„±ê³µ: {try_model}")
                    return result
                else:
                    logger.error(f"[extract_style] JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ ë‚´ìš©: {text[:500]}...")
                    raise ValueError("JSON not found in response")
                    
            except Exception as e:
                logger.warning(f"[extract_style] {try_model} ì‹¤íŒ¨: {e}")
                if try_model != models_to_try[-1]:
                    continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        logger.error("[extract_style] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨")
        raise Exception("ìŠ¤íƒ€ì¼ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_gemini_service: Optional[GeminiService] = None

def get_gemini_service() -> GeminiService:
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiService()
    return _gemini_service


